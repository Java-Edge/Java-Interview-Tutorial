生产环境需考量各种因素，结合自身业务需求而制定。看一些考虑因素（以下顺序，可是分了顺序的哦）
# 1 OS
- Kafka不是JVM上的中间件吗？Java又是跨平台语言，把Kafka安装到不同的os有啥区别吗？
区别相当大！

Kafka的确由Scala/Java编写，编译后源码就是“.class”文件。部署到啥OS应该一样，但毋庸置疑，部署在Linux上的生产环境是最多的，具体原因你能谈笑风生吗？
## 1.1 I/O模型
I/O模型其实就是os执行I/O指令的方法，主流的I/O模型通常有5种类型：
1. 阻塞式I/O
e.g. Java中Socket的阻塞模式
2. 非阻塞式I/O
e.g. Java中Socket的非阻塞模式
3.  I/O多路复用
e.g. Linux中的系统调用`select`函数
4. 信号驱动I/O
e.g. epoll系统调用则介于第三种和第四种模型之间
5. 异步I/O
e.g. 很少有Linux支持，反而Windows系统提供了一个叫IOCP线程模型属于该类

I/O模型与Kafka的关系几何？Kafka Client 底层使用了Java的selector，而selector
- 在Linux上的实现机制是epoll
- 在Windows平台上的实现机制是select

因为这点，Kafka部署在Linux上更有优势，能获得更高效的I/O性能。
## 1.2 数据网络传输效率
- Kafka生产和消费的消息都是通过网络传输，但消息保存在哪呢？
肯定是磁盘！

故Kafka需在磁盘和网络间进行大量数据传输。在Linux部署Kafka能够享受到零拷贝技术带来的快速数据传输特性。
## 1.3 社区生态
社区对Windows平台上发现的Kafka Bug不做任何承诺。
# 2 磁盘
## 2.1 机械硬盘 or SSD
- 前者便宜且容量大，但易坏！
- 后者性能优势大，但是贵！

建议是使用普通机械硬盘即可。
- Kafka虽然大量使用磁盘，可多是顺序读写操作，一定程度规避了机械磁盘最大的劣势，即随机读写慢。从这一点上来说，使用SSD并没有太大性能优势，机械磁盘物美价廉
- 而它因易损坏而造成的可靠性差等缺陷，又由Kafka在软件层面提供机制来保证
## 2.2 是否应该使用磁盘阵列（RAID）
使用RAID的主要优势：
- 提供冗余的磁盘存储空间
- 提供负载均衡

对于Kafka
- Kafka自己实现了冗余机制，提供高可靠性
- 通过分区设计，也能在软件层面自行实现负载均衡

RAID优势也就没有那么明显了。虽然实际上依然有很多大厂确实是把Kafka底层的存储交由RAID，只是目前Kafka在存储这方面提供了越来越便捷的高可靠性方案，因此在线上环境使用RAID似乎变得不是那么重要了。

综上，追求性价比的公司可不搭建RAID，使用普通磁盘组成存储空间即可。使用机械磁盘完全能够胜任Kafka线上环境。
## 2.3 磁盘容量
集群到底需要多大？
Kafka需要将消息保存在磁盘上，这些消息默认会被保存一段时间然后自动被删除。
虽然这段时间是可以配置的，但你应该如何结合自身业务场景和存储需求来规划Kafka集群的存储容量呢？

假设有个业务
- 每天需要向Kafka集群发送1亿条消息
- 每条消息保存两份以防止数据丢失
- 消息默认保存两周时间

现在假设消息的平均大小是1KB，那么你能说出你的Kafka集群需要为这个业务预留多少磁盘空间吗？

计算：
- 每天1亿条1KB的消息，存两份
`1亿 * 1KB * 2 / 1000 / 1000 = 200GB`

- 一般Kafka集群除消息数据还存其他类型数据，比如索引数据
再为其预留10%磁盘空间，因此总的存储容量就是220GB

- 要存两周，那么整体容量即为
220GB * 14，大约3TB
- Kafka支持数据的压缩，假设压缩比是0.75
那么最后规划的存储空间就是0.75 * 3 = 2.25TB

总之在规划磁盘容量时你需要考虑下面这几个元素：
- 新增消息数
- 消息留存时间
- 平均消息大小
- 备份数
- 是否启用压缩
# 3 带宽
对于Kafka这种通过网络进行大数据传输的框架，带宽易成为瓶颈。

普通以太网络，带宽主要有两种：
- 1Gbps的千兆网络
- 10Gbps的万兆网络

以千兆网络为例，说明带宽资源规划。真正要规划的是所需的Kafka服务器的数量。假设机房环境是千兆网络，即1Gbps，现在有业务，其目标或SLA是在1小时内处理1TB的业务数据。

到底需要多少台Kafka服务器来完成这个业务呢？
### 计算
带宽1Gbps，即每秒处理1Gb数据
假设每台Kafka服务器都是安装在专属机器，即每台Kafka机器上没有混入其他服务
通常情况下你只能假设Kafka会用到70%的带宽资源，因为总要为其他应用或进程留一些资源。超过70%的阈值就有网络丢包可能性，故70%的设定是一个比较合理的值，也就是说单台Kafka服务器最多也就能使用大约700Mb带宽。

这只是它能使用的最大带宽资源，你不能让Kafka服务器常规性使用这么多资源，故通常要再额外预留出2/3的资源，即
`单台服务器使用带宽700Mb / 3 ≈ 240Mbps`
这里的2/3其实是相当保守的，可以结合机器使用情况酌情减少该值

有了240Mbps，可以计算1小时内处理1TB数据所需的服务器数量了。
根据这个目标，每秒需要处理2336Mb的数据，除以240，约等于10台服务器。
如果消息还需要额外复制两份，那么总的服务器台数还要乘以3，即30台。
# 总结
部署Kafka环境，一开始就要思考好实际场景下业务所需的集群环境，不能仅从单个维度上进行评估。

> 参考
> - Linux内核模型架构
> - Kafka核心技术与实战