# 03-BASE 还能撑多久？强一致性才是事务处理的终极奥义！

## 0 前言

分布式数据库“强一致性”包括数据一致性、事务一致性两个方面。本文谈事务一致性。

有人说ACID落伍，BASE为理论基础NoSQL才是主流。BASE是很宽泛定义，承诺有限。BASE意义只在放弃ACID的一些特性，从而更简单实现高性能和可用性，达到一个新平衡。但架构设计平衡往往是阶段性，随新技术突破，原平衡点也自然改变。不说分布式数据库，就连NoSQL也开始增加事务支持。ACID已是后浪。

## 1 事务ACID

数据库“事务”由多个操作构成的序列。1970年詹姆斯 · 格雷（Jim Gray）提出事务的ACID，将广义事务一致性具化到原子性、一致性、隔离性和持久性。他在*Transaction Processing Concepts and Techniques*的定义：

> **Atomicity**: *Either all the changes from the transaction occur (writes, and messages sent), or none occur.* 原子性：事务中的所有变更要么全部发生，要么一个也不发生。

> **Consistency**: *The transaction preserves the integrity of stored information.* 一致性：事务要保持数据的完整性。

> **Isolation**: *Concurrently executing transactions see the stored information as if they were running serially (one after another).* 隔离性：多事务并行执行所得到的结果，与串行执行（一个接一个）完全相同。

> **Durability**: *Once a transaction commits, the changes it made (writes and messages sent) survive any system failures.* 持久性：一旦事务提交，它对数据的改变将被永久保留，不应受到任何系统故障的影响。

ACID对数据库的重要度不同：

![](https://img-blog.csdnimg.cn/5bb441075ff34250ace2833d30890921.png)

### 1.1 一致性

存在感最低，可看作对 “事务”整体目标阐述。没提出任何具体需求，所以数据库中难寻针对性设计。

### 1.2 持久性

不仅是对数据库的基本要求。考究其定义，核心思想就是要应对系统故障。故障分为：

1. 存储硬件无损、可恢复的故障。主要依托预写日志（Write Ahead Log，WAL）保证第一时间存储数据。WAL采用顺序写，保证数据库低延时响应。WAL是单体数据库成熟技术，NoSQL和分布式数据库都借鉴过去了
2. 存储硬件损坏、不可恢复的故障。要用到日志复制技术，将本地日志及时同步到其他节点。实现方式有三种：
   1. 单体数据库自带的同步或半同步：半同步具有一定容错能力，实践更多
   2. 将日志存储到共享存储系统，后者通过冗余存储保证日志安全性，亚马逊Aurora就是，也称Share Storage
   3. 基于Paxos/Raft共识算法同步日志数据，分布式数据库中广泛使用。无论采用哪种，都是保证在本地节点之外，至少有一份完整日志可用于数据恢复


### 1.3 原子性

数据库区别其他存储系统的重要标志。

单体数据库时代，原子性问题已妥善解决，但向分布式架构转型，在引入不可靠网络因素后，原子性又成为挑战。

分布式架构支持原子性不容易，所以不少NoSQL选择绕过这问题，聚焦到那些对原子性不敏感的细分场景。如Google BigTable都不支持跨行事务。但这种妥协也造成NoSQL通用性不好。

本系列讨论分布式数据库是在分布式架构上实现的关系型数据库，就必须支持事务，先要支持原子性。原子性实现较复杂，目标却简单，和分成多级的隔离性不同，原子性只有支持、不支持。

### 1.4 隔离性

事务最复杂特性。隔离性分多个隔离级别，较低隔离级别就是在正确性妥协，将一些异常现象交给应用开发，从而获得更好性能。

事务模型发展过程就是在隔离性和性能间不断寻找更优平衡点。事务核心就是隔离性。而不同产品在事务一致性上的差别，也完全体现在隔离性的实现等级。

## 2 ANSI SQL-92（SQL-92）

最早、最正式的对隔离级别的定义，定义的隔离级别和异常现象：

![](https://img-blog.csdnimg.cn/b369d328ce8547a4ad9173913a375b55.png)

虽然SQL-92得到广泛应用，不少数据库也遵照该标准命名自己的隔离级别，但它对异常现象的分析还是过于简单。1995年Jim Gray等发表论文“[A Critique of ANSI SQL Isolation Levels](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf)”（以下简称Critique），对事务隔离性深入分析。Critique是数据库领域经典论文。

## 3 Critique：更严谨的隔离级别

### 3.1 幻读和写倾斜

丰富细化SQL-92内容，定义六种隔离级别和八种异常现象。

最关注快照隔离（Snapshot Isolation, SI）级。SQL-92可重复读（Repeatable Read, RR）与可串行化（Serializable）主要差别是幻读（Phantom）处理。似乎说解决幻读就是可串行化。但随Critique发表，快照隔离明确提出，这说法就不适用了，因为快照隔离能解决幻读，但：

- 无法处理写倾斜（Write Skew）
- 也不符合可串行化要求

翻译原因，有时写倾斜也称写偏序。因此，使用最广泛的隔离级别：已提交读、可重复读、快照隔离、可串行化。

幻读和写倾斜是通往最高隔离级别的两座大山。

### 3.2 Critique的幻读

事务T1特定查询条件获得一个结果集，事务T2插入新数据且符合T1刚执行的查询条件。T2提交成功后，T1再次执行同样查询，得到结果集增大。

#### 幻读 V.S 不可重复读

自然语义接近，都是在一个事务内用相同条件查询两次，但两次结果不一：

- 不可重复读，第二次结果集相对第一次，有些记录被修改（Update）或删除（Delete）
- 幻读是第二次结果集里出现第一次结果集没有的记录（Insert）。幻读是在第一次结果集的记录“间隙”中增加新记录。所以，MySQL将防幻读的锁命名为间隙锁（Gap Lock）。

### 3.3 写倾斜

跟幻读相比，写倾斜稍复杂。

箱子里有三个白球和三个黑球，两个事务（T1,T2）并发修改，不知道对方的存在。T1要让6个球都变成白色；T2则希望6个球都变成黑色。

![](https://static001.geekbang.org/resource/image/91/fa/91e75e61d921fb21cebfdba8879806fa.jpg)

![](https://static001.geekbang.org/resource/image/dd/be/ddce93423da417ef495b2bbc7c3090be.jpg)

你看，最终的执行结果是，盒子里仍然有三个黑球和三个白球。如果你还没有发现问题，可以看看下面我画的串行执行的效果图，比较一下有什么不同。

![](https://static001.geekbang.org/resource/image/85/83/8502cf4cf0f6fe61db1692bd1a945883.jpg)

如果先执行T1再执行T2，6个球都会变成黑色；调换T1与T2的顺序，则6个球都是白色。

根据可串行化的定义，“多事务并行执行所得到的结果，与串行执行（一个接一个）完全相同”。比照两张图，很容易发现事务并行执行没有达到串行的同等效果，所以这是一种异常现象。也可以说，写倾斜是一种更不易察觉的更新丢失。

为搞清Critique中六种隔离级别的强弱关系以及相互间的差距，我截取了原论文的一张配图。

![](https://static001.geekbang.org/resource/image/0d/aa/0d81415e08f4507d5f3f3ff6f99a99aa.jpg)

你可以看到“快照隔离”与“可重复读”在强度上并列，“已提交读”则弱于这两者。事实上，今天大多数数据库支持的隔离级别就在这三者之中。

### 3.4 快照隔离 & MVCC

“快照隔离”为啥被SQL-92漏掉？SQL-92主要考虑基于锁（Lock-base）的并发控制，而快照隔离实现基础是MVCC，当时MVCC应用不普遍。后来MVCC成为重要技术，一些教材将MVCC作为独立选择，与乐观并发控制和悲观并发控制并列。现代数据库中MVCC已成为底层技术，更高效实现乐观或悲观并发控制。有MVCC基础，快照隔离成为普遍存在的隔离级别。

## 4 隔离性的产品

为啥不支持最高级别可串行化？学术界很久没找到高效的并发控制技术。很多数据库声称“可串行化”，但只是形象工程，因为都采用两阶段封锁协议，性能无法满足生产要求。少数产品尝试已取得进展：

- 第一个方向，真正串行化实现“可串行化”。多线程并发在性能上更优，但Redis和VoltDB确实通过串行化执行事务获得不错性能。考虑到VoltDB作为一款分布式数据库的复杂度，成功更难得。部分原因可能在于内存的大量使用，加速数据计算VoltDB以存储过程为逻辑载体的方式，也使事务有更多优化机会
- 如第一个方向剑走偏锋，第二个方向就是硬桥硬马。在并发技术继续做。PostgreSQL在2008年提出Serializable Snapshot Isolation (SSI)，即可串行化。而后，兼容PostgreSQL生态的CockroachDB，也同样选择支持SSI，而且是唯一支持的隔离级别

## 5 分布式数据库的强一致性

数据一致性和事务一致性共同构成分布式数据库的强一致性。

![](https://img-blog.csdnimg.cn/722589bf794d4b74b28aff32b1e452a3.png)

论文“Highly Available Transactions: Virtues and Limitations”，[Jepsen网站的简化版](https://jepsen.io/consistency)。

树状结构左右两分支体现事务一致性和数据一致性的各级别及强弱关系，根节点则体现分布式数据库的一致性来自两者的融合。图中使用不同颜色，这是区别不同的一致性级别所需付出的性能代价。

分布式数据，最高级别一致性是严格串行化（Strict Serializable），Spanner的“外部数据一致性”可视为与 “Strict Serializable” 等效。但两条路径各自实现难度及性能上的损耗，少有分布式数据库在顶端汇合。即使强大的Spanner也提供有界旧一致性（Bounded Stale），以平衡性能和一致性之间的冲突。

分布式数据库产品的“一致性”实现现状：

![](https://img-blog.csdnimg.cn/3d40e45e23994380af1a608823e9b2c4.png)

OceanBase 2.2版本增加对“可串行化”支持，但这是被Oracle重新定义的“可串行化”，在这级别OceanBase和Oracle一样都会写倾斜。所以，这不是我们标准的隔离级别，没体现在表格。

## 6 总结

1. 数据一致性关注的是单对象、单操作在多副本上的一致性，事务一致性则是关注多对象、多操作在单副本上的一致性，分布式数据库的一致性是数据一致性与事务一致性的融合。
2. 广义上的事务一致性被细化为ACID四个方面，其中原子性的实现依赖于隔离性的并发控制技术和持久性的日志技术。
3. 隔离性是事务的核心。降低隔离级别，其实就是在正确性上做妥协，将一些异常现象交给应用系统的开发人员去解决，从而获得更好的性能。所以，除“可串行化”以外的隔离级别，都有无法处理的异常现象。
4. 研究人员将隔离级别分为六级，你需要重点关注其中四个，分别是已提交读、可重复读、快照隔离、可串行化。前三者是单体数据库或分布式数据库中普遍提供的，可串行化仅在少数产品中提供。

严格意义上，分布式数据库的“强一致性”意味着严格串行化（Strict Serializable），目前我们熟知的产品中只有Spanner达到了这个标准，其同时也带来了性能上的巨大开销。如果我们稍稍放松标准，那么“数据一致性”达到因果一致性且“事务一致性”达到已提交读，即可认为是相对的“强一致性”。还有一点非常重要，分布式数据一致性并不是越高越好，还要与可用性、性能指标结合，否则就成了形象工程。

## 7 FAQ

事务持久性部分提到预写日志（WAL），它可以保证在系统发生故障时，数据也不会丢失。但是，如果写日志成功，而写数据表失败，又要如何处理呢？根据自己的经验，讲讲该如何设计这过程？

如写日志成功，但写数据表失败，可采用回滚机制保证数据一致性。可在写数据表之前，先在日志中记录一个“撤销”操作，表示如果写数据表失败，需要回滚到之前的状态。如果写数据表成功，则在日志中记录一个“提交”操作，表示当前状态已经是有效状态。在系统发生故障需要恢复时，可以根据日志中的操作来恢复数据表的状态，保证数据的一致性。



MySQL RR与RC都分：

- 当前读

  当前读才加锁

- 快照读

  都不加锁

RR快照读可消除幻读，因为这是事务开始时的快照一致性读，而RC是语句快照一致性读。

数据块未能及时落盘，重新启动数据库会进行实例恢复，从最后的检查点开始将redo进行前写和回滚，这样就能保证数据块与redo一致了，实例恢复后，数据库就可以对外访问。

正常写入过程中WAL和内存中的数据也要保证一致，因为第一时间数据库通常是不会将数据表落盘的，内存中有数据即可对外服务。

Q：快照隔离相当于比RR多解决了幻读，文章说是MVCC功能特性，但MVCC并不能解决幻读，真正解决幻读的是Gap Lock（MySQL）？而且RR也可用MVCC实现？

A：不是说MVCC可解决幻读。MVCC是底层技术，在此基础更易实现快照隔离，而快照隔离是要解决幻读，否则就不是标准的快照隔离。

Q：实际工程中幻读在啥时有问题？似乎绝大多数情况，一个事务看见其他事务的创建或删除记录都不是问题？

A：幻读问题通常出现在高并发事务环境，尤其执行大量插入、更新或删除时。此时，一个事务可能看到其他事务已提交的更改，但提交自己的更改时，却发现一些新数据。

假设有两个事务同时向一个订单表插数据：

- 第一个事务插入了一条订单记录，但还没提交
- 第二个事务也尝试插入一条订单记录，但由于第一个事务还没提交，所以第二个事务会被阻塞
- 然后，第一个事务提交其订单记录，第二个事务就继续执行
- 但此时第二个事务会发现多一条订单记录，这就是幻读

为避免幻读，可用行级锁或MVCC等。

![](https://img-blog.csdnimg.cn/ab698085bcc84ee9a5c68b789b6c6847.png)

预写日志就是redo日志，若redo日志成功证明已落盘，此时数据可根据redo日志异步的刷回磁盘，写数据表失败应该就是后面异步写回出现问题，我们只需重演redo日志。

既然说分布式数据库事务，也该说说分布式事务，毕竟定义了数据库是分片的，如事务涉及多个机器，就得上分布式事务。https://blog.csdn.net/weixin_43705457/article/details/105443927

WAL意义在于写时机，一定是同步写入，WAL如果不能写成功，SQL提交一定是失败的。同时，与WAL相关的，数据库也要处理内存中的数据与WAL协同的问题，因为多数的数据库都是第一时间写入内存结构的，而后再根据不同策略落盘。



ANSI SQL 92没考虑快照隔离的原因是MVCC技术的不广泛？为啥MVCC使用不广泛就不能考虑SI呢？这之间的推导关系能再阐述？
一般事务操作流程是WAL+内存写。WAL是持久化的，即硬件无故障的话就不会丢失。如在内存写时崩溃，那数据库重启就要检查日志，如日志表明已提交，而真正数据还没写完，则要重放。需要一套机制来判断日志中的事务是否已提交等。

Q：解决写倾斜主要就是加写锁，但这严重影响并发性能？

A：是，传统方案是使用锁（S2PL）解决，但性能较差。还有其他悲观协议，如串行化图检测（SGT）。

日志落盘后，即可根据日志进行数据表的重写，日志在，数据表就可根据最近的checkpoint恢复。

SI隔离级别是MVCC，RR也可用MVCC，不过之前没有这种技术，都用2PL。SI主要通过Gap lock来解决RR的幻读？因为光一个MVCC是解决不了幻读的。

MVCC是底层技术。Gap Lock只是MySQL的实现技术，也不是SI的唯一实现方式。

Q：redo log何时刷盘？完全同步太慢，批处理又可能丢数据？

A：redo log是接到客户端请求后立即落盘，同步方式包括异步复制，半同步复制和全复制，若对RPO有要求，选择半同步复制多些。