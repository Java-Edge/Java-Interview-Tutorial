# 12-分布式架构、性能优化、场景设计面试实战

## 分布式架构面试连环炮

接下来说一下分布式架构中的一些面试连环炮，主要从链路监控、事务提交、这几个方面来说一下

### 分布式系统链路监控

主要说一下分布式系统链路监控实现的原理是什么

分布式系统链路监控主要适用于进行性能监控和故障排查，国内常用的有 CAT（大众点评的） 和 zipkin（Twitter 的）

其实链路监控主要就是做一个框架，包含一个客户端服务端：

- 在需要监控的系统中集成客户端，对一些需要监控的数据，调用链路监控的客户端 API 发送到服务端去
- 服务端将监控数据进行落库以及生成报表



我之前面试的时候，也碰到过一个面试官给我说，让我设计一个分布式系统链路监控的方案，画了一个图如下（这里主要参考了美团点评的 CAT 监控框架，美团技术团队官方文章：[深度剖析开源分布式监控CAT](https://tech.meituan.com/2018/11/01/cat-in-depth-java-application-monitoring.html)：

这里我也简单说一下流程：

1. 应用 A 在调用接口时，生成一个唯一的监控 id，这个监控 id 由：请求入口 id + 服务调用 id + 上游服务 id + 调用时间组成，保证 id 的唯一性，并且可以判断这个链路调用方向是如何的
2. 之后通过数据监控的客户端将监控数据发送给服务端，可以通过 MQ 发送，也可以自己写一个 Netty 逻辑，通过 Netty 发送
3. 服务端收到监控数据后，将数据落库，在 MySQL 和时序数据库中都存放一份，在数据的查询使用时序数据库速度比较快，而时序数据库中不可以修改数据，所以还是要在 MySQL 存储一份（对这里我了解的也不太多，如果感兴趣可以详细了解一下具体数据的存储）
4. 之后就是前端生成报表展示了

![数据监控方案](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/数据监控方案.png)



 

### 分布式事务中的两阶段提交和三阶段提交

分布式事务的两阶段提交（Two-phase Commit，简称2PC）是分布式系统中用于确保事务原子性的协议。它由两个主要阶段组成：



1. **准备阶段（Prepare Phase）**：
   - 事务协调者（Transaction Coordinator）向所有参与者（Participants）发送准备请求（Prepare Request），询问它们是否准备好提交事务。
   - 参与者执行事务操作，但不提交事务。它们将操作结果记录在本地日志中，以便在需要时可以回滚。
   - 参与者向协调者发送准备响应（Prepare Response），告知它们是否准备好提交事务。

2. **提交阶段（Commit Phase）**：
   - 如果所有参与者都报告准备就绪（Prepared），协调者向所有参与者发送提交请求（Commit Request），指示它们提交事务。
   - 如果有任何一个参与者报告未准备好（Not Prepared），协调者向所有参与者发送回滚请求（Rollback Request），指示它们回滚事务。
   - 参与者根据协调者的指令执行提交或回滚操作，并将结果（Commit Acknowledgment 或 Rollback Acknowledgment）发送回协调者。
   - 协调者收到所有参与者的确认后，事务提交或回滚过程完成。

![1705900845214](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705900845214.png)

两阶段提交协议的目的是确保分布式事务的一致性。在分布式系统中，事务可能涉及多个节点，每个节点上的操作必须同时成功或同时失败，以保持数据的完整性和一致性。

然而，两阶段提交协议也存在一些问题，主要包括：

- **同步阻塞**：在准备阶段，所有参与者必须等待协调者的提交或回滚指令，这可能导致资源锁定和系统响应延迟。
- **单点故障**：如果协调者在提交阶段失败，而没有发送提交指令，那么所有参与者将无法提交事务，可能导致数据不一致。
- **协调者过载**：协调者需要处理所有事务的提交和回滚请求，这可能导致协调者成为性能瓶颈。
- **超时和网络分区**：在网络不稳定的环境中，协调者和参与者之间的通信可能会超时，导致事务无法完成。

为了解决这些问题，有些系统可能会采用改进的两阶段提交协议，或者使用其他分布式事务处理机制，如三阶段提交（3PC）、补偿事务（Compensating Transactions）或最终一致性（Eventual Consistency）等。

> 分布式协调框架 ZooKeeper 使用的就是 2PC，由于 2PC 是同步阻塞的，因此 zk 适合小集群部署



 分布式事务的三阶段提交（Three-phase Commit，简称3PC）是一种用于确保分布式系统中事务的原子性和一致性的协议。它在两阶段提交（Two-phase Commit，简称2PC）的基础上增加了一个额外的阶段，以解决2PC中可能存在的同步问题。三阶段提交包括以下三个阶段：

1. **准备阶段（CanCommit Phase）**：
   - 事务协调者（Coordinator）向所有参与者（Participants）发送`CanCommit`消息，询问是否可以执行事务提交操作。
   - 参与者收到`CanCommit`消息后，会执行事务操作，并将操作结果记录在本地日志中，但不提交事务。
   - 参与者会将操作结果（可以提交或不能提交）反馈给协调者。

2. **预提交阶段（PreCommit Phase）**：
   - 如果协调者收到了所有参与者的`CanCommit`响应，并且所有参与者都表示可以提交，协调者会发送`PreCommit`消息给所有参与者。
   - 参与者收到`PreCommit`消息后，会执行事务的预提交操作，并将结果（成功或失败）记录在本地日志中，然后向协调者发送`Ack`消息。
   - 如果协调者收到了所有参与者的`Ack`消息，或者在超时时间内没有收到任何`Ack`消息，协调者会认为事务可以提交。

3. **提交阶段（DoCommit Phase）**：
   - 协调者向所有参与者发送`DoCommit`消息，指示它们提交事务。
   - 参与者收到`DoCommit`消息后，会正式提交事务，并将提交结果记录在本地日志中。
   - 参与者提交事务后，会向协调者发送`Ack`消息。
   - 协调者收到所有参与者的`Ack`消息后，事务提交过程完成。

![1705900664987](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705900664987.png)

三阶段提交协议的目的是为了解决两阶段提交协议中的同步问题，特别是在网络分区（Network Partition）或协调者故障的情况下。在2PC中，如果协调者在发送`Commit`消息后崩溃，而参与者没有收到`Commit`消息，那么参与者将无法提交事务，这可能导致数据不一致。通过引入预提交阶段，3PC允许参与者在提交之前确认他们已经准备好，从而减少了这种不一致性的风险。

然而，三阶段提交协议并没有完全解决2PC的所有问题，它仍然可能面临一些同步问题，例如，如果协调者在发送`PreCommit`消息后崩溃，而参与者在没有收到`DoCommit`消息的情况下也崩溃，那么参与者可能会在重启后尝试提交事务，这可能导致数据不一致。因此，在实际应用中，需要根据系统的特定需求和可用资源来选择最合适的事务处理策略。

**总结一下：2PC 由于只有两个阶段，性能是比 3PC 要好的，而 3PC 通过增加了一个阶段，提供了更好的故障恢复能力**

 



### 唯一 ID 生成机制中的 Snowflake 算法的时钟回拨问题如何解决？

 Snowflake 算法是由Twitter开发的一个分布式ID生成算法，用于在分布式系统中生成唯一且有序的ID。它的核心思想是将一个64位的长整型数字分割成不同的部分，每个部分代表不同的信息，从而确保ID的唯一性和有序性。Snowflake算法的ID结构通常如下：

- 第1位：符号位，始终为0，表示正数。
- 第2-41位：时间戳，使用41位来表示当前时间与预设的起始时间（如1970年1月1日）之间的毫秒差。这样可以支持大约69年的时间范围。
- 第42-52位：数据中心ID，用于区分不同的数据中心。通常使用5位或10位，可以支持最多32个数据中心。
- 第53-62位：机器ID，用于区分不同的机器。同样使用5位或10位，可以支持最多1024台机器。
- 第63-64位：序列号，用于在同一个毫秒内生成多个ID。通常使用12位，可以支持4096个序列号。



在使用 Snowflake 生成的唯一 ID 有 41 位是时间戳，那么假如系统时钟回拨，系统时间比上次生成唯一 ID 的时间小，那么可能会生成重复的 ID

**为什么会发送时钟回拨呢？**

当前的机器的会跟一台基准时间服务器进行时间校准，如果你的机器的时间跑的稍微快了一点，此时跟基准时间服务器进行了校准，你的时间被校准后就倒退回去了



**怎么解决呢？**

如果发生了时钟回拨，此时你看看时钟回到了之前的哪一毫秒里去，直接接着在那一毫秒里的最大的 ID 继续自增就可以了



## 性能优化面试实战

### 优化数据库连接池

**高并发场景下的数据库连接池应该如何进行优化？**

 数据库连接池中存放的就是数据库的连接，要对连接池优化，可以从建立连接的超时时间、连接池中的连接数量限制来考虑

简单来说，就是如果建立连接或者发送请求失败，不要一直阻塞等待，设置超时时间，失败了就断开重连就好了！

1. **maxWait 设置**

`maxWait`参数表示从连接池中获取连接时的最大等待时间，单位是毫秒

推荐设置值为 1000，表示等待 1s 之后还没有获取链接，就算等待超时

如果 maxWait 设置为 -1，那么在高并发场景下，瞬间连接池中的连接都被占用了，大量的请求拿不到连接，无限等待，最终导致 Tomcat 服务器中的线程耗尽，无法对外继续提供服务

2. **connectionProperties 设置**

可以放 `connectionTimeout` 和 `socketTimeout` 属性，表示 `建立TCP连接的超时时间` 和 `发送请求后等待响应的超时时间`

推荐设置值为：

- connectionTimeout = 1200
- socketTimeout = 3000

不设置这两个值的话，如果高并发场景下，万一碰到了网络问题，导致和数据库的 Socket 连接异常无法通信，那么服务端的 Socket 一直阻塞等待响应，其他请求就无法获取这个连接处理自己的任务

通过设置这两个值，保证在一定时间没有处理完，就算超时，断开连接重连

3. **maxActive 设置**

最大连接池数量，一般建议是设置个20就够了

如果确实有高并发场景，可以适当增加到 3~5 倍，但是不要太多，其实一般这个数字在几十到 100 就很大了，因为这仅仅是你一个服务连接数据库的数量，还有其他的服务，而且数据库整体能承受的连接数量是有限的

连接越多不是越好，数据库连接太多了，会导致 CPU 负载很高，可能反而会导致性能降低的，所以这个参数你一般设置个 20，最多再加几十个就差不多了

 



### 优化系统 TPS

**如果压测的时候发现系统的 TPS 不达标，此时应该如何优化系统？**

这里说一下优化系统的思路，首先，TPS 不达标，一定要去检查 SQL，比如存不存在比较慢的 SQL，比如一个 SQL 执行 500ms 或者 1s，那你线程再多，也处理不了多少的请求，所以要先检查慢 SQL，`第一步：对数据库建立索引进行优化`

接下来检查有没有耗时较长的接口，比如一个接口耗时 500ms 甚至 1s，不过接口耗时太长一般都是 SQL 太慢，如果 SQL 优化过之后，接口耗时还是很长，`第二步：可以考虑异步化或多线程进行优化`

还可以对 Tomcat 进行优化，通过修改 Tomcat 的参数，Tomcat 默认最大线程数是 200 个，那么可以扩大至 500 个或者 800 个，并且加大 Tomcat 中等待队列的长度以及连接建立数量的限制，主要是 3 个参数：maxThreads、acceptCount、maxConnections，`第三步：对 Tomcat 进行优化`

代码方面优化做完了，接下来就可以对机器方面进行优化，比如一台服务单机抗 800 个请求，你需要抗 3000 个请求，那么就再扩充 3 台机器，总共 4 台机器，每秒就可以抗 3200 个请求，`第四步：扩充机器`





### Tomcat 调优

**为什么对 SpringBoot 嵌入式的 Web 服务器 Tomcat 进行调优？**

- Tomcat三大配置maxThreads、acceptCount、maxConnections

  1. 最大线程数maxThreads

     决定了Web服务器最大同时可以处理多少个请求任务数量

      线程池最大线程数，默认值200

  2. 最大等待数accept-count

     是指队列能够接受的最大等待数，如果等待队列超了请求会被拒绝

      默认值100

  3. 最大连接数MaxConnections

     是指在同一时间，Tomcat能够接受的最大连接数，如果设置为-1，则不限制连接数

     最大连接数和最大等待数关系：当连接数达到最大连接数后还会继续接请求，但不能超过最大等待数，否则拒绝连接

**最大线程数的值应该设置多少合适呢？**

- 需要基于业务系统的监控结果来定：RT（响应时间）均值很低不用设置，RT均值很高考虑加线程数
- 接口响应时间低于100毫秒，足以产生足够的TPS
- 如果没有证据表明系统瓶颈是线程数，则不建议设置最大线程数
- 个人经验值：1C2G线程数200，4C8G线程数800

**调优结论：在高负载场景下，TPS提升近1倍，RT大幅降低，异常占比降低**

注意：配置修改需确认配置生效，否则再苦再累也白搭！



> **Tomcat 调优配置**

1. **修改配置**

在 SpringBoot 项目中的 yml 文件中，对嵌入的 Tomcat 进行如下配置：

```yaml
# Tomcat的maxConnections、maxThreads、acceptCount三大配置，分别表示最大连接数，最大线程数、最大的等待数，可以通过application.yml配置文件来改变这个三个值，一个标准的示例如下：
server.tomcat.uri-encoding: UTF-8
# 思考问题：一台服务器配置多少线程合适？
server.tomcat.accept-count: 1000 # 等待队列最多允许1000个请求在队列中等待
server.tomcat.max-connections: 20000 # 最大允许20000个链接被建立
## 最大工作线程数，默认200, 4核8g内存，线程数经验值800
server.tomcat.threads.max: 800 # 并发处理创建的最大的线程数量
server.tomcat.threads.min-spare: 100 # 最大空闲连接数，防止突发流量
```



修改之后，我们使用 SpringBoot Actuator 来管理和监听应用程序

2. **集成 Actuator**

官方文档：https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.enabling

- 引入依赖

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>

```

- 配置文件暴露监控点

```yaml
# 暴露所有的监控点
management.endpoints.web.exposure.include: '*'
# 定义Actuator访问路径
management.endpoints.web.base-path: /actuator
# 开启endpoint 关闭服务功能
management.endpoint.shutdown.enabled: true
# 暴露的数据中添加application label
management.metrics.tags.application: hero_mall
```



访问 http://localhost:8081/actuator 可以查看所有配置

![1705979157601](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705979157601.png)

找到configprops，访问链接，搜索tomcat查看是否配置成功

![1705979167537](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705979167537.png)







### Web 容器优化

**将Tomcat容器升级为Undertow**

Undertow是一个用Java编写的灵活的高性能Web服务器，提供基于NIO的阻塞和非阻塞API。

- 支持Http协议
- 支持Http2协议
- 支持Web Socket
- 最高支持到Servlet4.0
- 支持嵌入式

SpringBoot的web环境中默认使用Tomcat作为内置服务器，其实SpringBoot提供了另外2种内置的服务器供我们选择，我们可以很方便的进行切换。

- Undertow红帽公司开发的一款基于 NIO 的高性能 Web 嵌入式服务器 。轻量级Servlet服务器，比Tomcat更轻量级没有可视化操作界面，没有其他的类似jsp的功能，只专注于服务器部署，因此undertow服务器性能略好于Tomcat服务器；
- Jetty开源的Servlet容器，它是Java的web容器。为JSP和servlet提供运行环境。Jetty也是使用Java语言编写的。



> **配置Undertow**

1. 在spring-boot-starter-web排除tomcat

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-web</artifactId>
  <exclusions>
    <exclusion>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-tomcat</artifactId>
    </exclusion>
  </exclusions>
</dependency>
```

1. 导入其他容器的starter

```xml
<!--导入undertow容器依赖-->
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-undertow</artifactId>
</dependency>
```

1. 配置

```yaml
# 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接
server.undertow.threads.io: 800
# 阻塞任务线程池, 当执行类似servlet请求阻塞IO操作, undertow会从这个线程池中取得线
程
# 默认值是IO线程数*8
server.undertow.threads.worker: 8000
# 以下的配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内
存管理
# 每块buffer的空间大小越小，空间就被利用的越充分，不要设置太大，以免影响其他应用，合
适即可
server.undertow.buffer-size: 1024
# 每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-region
# 是否分配的直接内存(NIO直接分配的堆外内存)
server.undertow.direct-buffers: true
```

小结：

- 更换了服务容器之后，RT更加平稳，TPS的增长趋势更平稳，异常数（超时3s）几乎为0。
- 在低延时情况下，接口通吐量不及Tomcat。
- 稳定压倒一切，如果只是写json接口，且对接口响应稳定性要求高，可以选用Undertow





## 微信亿级朋友圈的社交系统设计

先来说一下业务需求吧：

- 每个用户可以发朋友圈，可以点赞，评论
- 可以设置权限，不看某些人朋友圈、不让某些人看你的朋友圈
- 可以刷朋友圈中其他人的动态

> 对于这样的系统设计，主要从业务来考虑如何设计，比如不能让用户等太久，那么从哪些方面可以优化速度，这些思想在所有的系统设计中都是 `通用` 的



### 发送朋友圈的流程

一般发送朋友圈是一段文字 + 几张图片或者视频，那么如果视频和图片较大，上传是比较慢的，如果等上传到服务器之后再返回用户成功，那用户可能要等 2-3 秒，界面一直在转圈，用户肯定会感到很难受哈

因此点击发送朋友圈的操作，要设计成异步的，点击发送之后，先将数据保存在本地缓存里，再通过异步操作将数据上传服务器，保存在本地成功后，就可以返回用户发布成功了，再异步的向服务器上传即可

那么如果不保存在本地，也可以将视频和图片就近上传到 CDN 中（当然也可以先保存在本地，再上传到 CDN 中），传到 CDN 的话也是很快的，之后再将发送请求到服务端，包括图片的 CDN 地址、视频的 CDN 地址、文字内容，并且将朋友圈的权限给写到朋友圈的发布表中去

之后，再通过离线的批处理（后台处理）将你刚刚发布的朋友圈给写入到好友的时间线表中，让好友也可以刷到你发布的朋友圈

![1705916309531](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705916309531.png)



那么还有**朋友圈的权限设置**，比如不让某人看，或者不看某些人，这些权限肯定是要缓存在本地的，而且权限的数据符合写少读多的特性的，用缓存来做很合适，如果你的好友的朋友圈权限设置发生了变化，那么可以发送一个通知，将你和好友的本地缓存都更新成新的数据

那么每次你刷新朋友圈，会根据你和好友的朋友圈的权限结合起来进行判断，看你是否有权限看到这条朋友圈





### 高并发的朋友圈点赞系统架构

点赞功能：可以点赞，可以取消点赞

基于 Redis 来设计点赞系统就可以，微信的朋友圈点赞和评论只有好友之间才可以看到的

每个朋友圈动态都在 Redis 中通过 set 集合来存放谁来给你点赞了，这样点赞的人和数量都可以从 redis 中直接获取，使用 smembers 和 scard 命令

那么你的朋友圈被 A 点赞了，B和你俩也是好朋友，那么 B 刷到你的朋友圈时，对你和 B 的共同好友通过 `sismember A` 来判断 A 是否给这条朋友圈点赞了，将共同好友的点赞给展示出来

对于评论的话，存在表中，也是将共同好友的评论给展示出来即可

如果是重复点赞其实也没有关系，在 Redis 的 set 中本来就会去重，因此不会出现重复点赞的情况



## 生产环境面试实战

### CPU 占用率 100% 该怎么解决

这属于是生产环境中的问题了，主要考察有没有 linux 中排查问题的经验，以及对 linux 排查问题的命令是否熟悉

1、首先查看 cpu 使用率

显示 cpu 使用率，执行完该命令后，输入 P，按照 cpu 使用率排序

使用 `top -c` 命令，找到占用 cpu 最多的进程 id（找 java 项目的）

2、查看占用 cpu 最多的进程中每个线程的资源消耗

通过 `top -Hp <进程id>` 命令，显示这个进程中所有【线程】的详细信息，包括每个线程的 CPU 使用率、内存使用情况、线程状态

找到 cpu 使用率最高的那个 java 进程，记下进程 id

3、将占用 cpu 最高的线程的线程 id 转成 16 进制

通过 `printf "%x\n" <线程id>` 命令输出这个线程 id 的 16 进制

4、定位哪段代码导致的 cpu 使用率过高：jstack 43987 | grep '0x41e8' -C5--color'

通过命令 `jstack <进程id> | grep '<16进制线程id>' -C5--color` 定位到占用 cpu 过高的代码

jstack 生成该进程的堆栈信息，通过线程的 16 进制线程 id 过滤出指定线程的信息

-C5 表示显示匹配行的 5 行上下文

--color：高亮显示，方便阅读





### 线上机器的进程用 kill 命令杀不死怎么办?

这也是生产环境的问题，还是考察对 linux 命令了不了解，可以看一下，扩展一下思路

这种情况下，一般是因为你使用 kill 命令杀的这个进程是一个子进程，这是因为子进程释放了资源，但是没有得到父进程的确认，就导致这个子进程变成了 `僵尸进程`，也就是 zombie 状态

这种情况，一般将这个僵尸进程的父进程给 kill 掉即可

1. 先找到这个僵尸进程

使用命令 `ps aux`，找到 STAT 这一栏为 Z 的进程，就是僵尸进程，记下进程 id

2. 找到僵尸进程的父进程 id

使用命令 `ps -ef | grep <僵尸进程id>`

3. 杀死父进程 id

通过 kill 命令杀死父进程即可





### 如果线上机器磁盘快要写满了，该怎么办？

其实线上机器的磁盘写满，基本上都是日志导致磁盘写满了，这里考察的就是 linux 中查看磁盘占用的命令

1. 查看磁盘使用情况

使用命令 `df -h` 查看磁盘的使用情况

2. 清楚比较老的日志

找到系统部署的位置，找一下日志在哪里存储，删除掉一些日期比较旧的日志即可

3. 预防

可以写一个 shell 脚本，定时删除 7 天之前的日志数据



**快捷查找：**

可以通过命令 

`find / -size +100M | xargs ls -lh`

快速找到在根目录下，大于 100M 大小的文件



也可以使用命令

`du -h > fs_du.log`

会扫描当前执行命令的目录以及子目录中磁盘的使用情况，并将结果输出到 fs_du.log 文件中

也可以执行扫描目录，例如扫描 /path 目录下

`du -h /path > fs_du.log`







