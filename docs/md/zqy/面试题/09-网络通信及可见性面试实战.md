# 09-网络通信及可见性面试实战

## 网络通信面试实战

### Socket 工作原理

Socket 是应用层与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口，其实就是一个门面模式，将底层复杂的通信操作给封装起来对外提供接口。

简单来说就是 Socket 把 TPC/IP 协议给封装了起来，我们的程序进行网络通信都是通过 Socket 来完成的！

也就是说当两台设备进行通信时，是通过 Socket 进行通信的，接下来通过 Java 代码来了解一下如何通过 Socket 进行网络通信：

**服务端：**

```java
public class Server {
    public static void main(String[] args) {
        int port = 1234; // 服务器监听的端口号

        try (ServerSocket serverSocket = new ServerSocket(port)) {
            System.out.println("服务器启动，等待客户端连接...");

            // 等待客户端连接
            Socket clientSocket = serverSocket.accept();
            System.out.println("客户端已连接：" + clientSocket.getInetAddress().getHostAddress());

            // 获取输入流
            InputStream input = clientSocket.getInputStream();
            BufferedReader reader = new BufferedReader(new InputStreamReader(input));

            // 读取客户端发送的消息
            String received = reader.readLine();
            System.out.println("接收到消息: " + received);

            // 获取输出流
            OutputStream output = clientSocket.getOutputStream();
            PrintWriter writer = new PrintWriter(output, true);

            // 回显客户端发送的消息
            writer.println("服务器回显: " + received);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```



**客户端：**

```java
public class Client {
    public static void main(String[] args) {
        String serverAddress = "localhost"; // 服务器地址
        int port = 1234; // 服务器监听的端口号

        try (Socket socket = new Socket(serverAddress, port)) {
            System.out.println("连接到服务器...");

            // 获取输出流
            OutputStream output = socket.getOutputStream();
            PrintWriter writer = new PrintWriter(output, true);

            // 向服务器发送消息
            writer.println("Hello, Server!");

            // 获取输入流
            InputStream input = socket.getInputStream();
            BufferedReader reader = new BufferedReader(new InputStreamReader(input));

            // 读取服务器回显的消息
            String response = reader.readLine();
            System.out.println("接收到服务器的回显: " + response);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```





### BIO、NIO和AIO

面试中问到网络相关的内容，其中 BIO、NIO 的内容肯定是必问的，AIO 可以了解一下，一定要清楚 BIO 和 NIO 中通信的流程

我也画了两张图，可以记下这两张图

- **AIO：**

从 Java.1.7 开始，Java 提供了 AIO（异步IO），Java 的 AIO 也被称为 “NIO.2”

Java AIO 采用`订阅-通知`模式，应用程序向操作系统注册 IO 监听，之后继续做自己的事情，当操作系统发生 IO 事件并且已经准备好数据时，主动通知应用程序，应用程序再进行相关处理

（Linux 平台没有这种异步 IO 技术，而是使用 epoll 对异步 IO 进行模拟）



- **BIO：**

BIO 即同步阻塞 IO，服务端实现模式为一个连接对应一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理

`BIO简单工作流程：`

1. 服务器端启动一个 ServerSocket，用于接收客户端的连接
2. 客户端启动 Socket 与服务器建立连接，默认情况下服务器端需要对每个客户端建立一个线程与之通讯（并且与每一个可u后端有一个对应的 Socket）
3. 客户端发出请求后, 先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝
4. 如果服务端有对应线程处理
   - 客户端进行读取，则线程会被阻塞直到完成读取
   - 客户端进行写入，则线程会被阻塞直到完成写入

使用 BIO 通信的流程图如下：

![1705479146307](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705479146307.png)



`BIO存在问题：`

1. 当并发量较大时，需要创建大量线程来处理连接，比较占用系统资源
2. 连接建立之后，如果当前线程暂时没有数据可读，则线程会阻塞在 Read 操作上，造成线程资源浪费

- **NIO：**

从 Java1.4 开始，Java 提供了 NIO，NIO 即 “Non-blocking IO”（同步非阻塞IO）

NIO 的几个核心概念：

1. Channel、Buffer：BIO是基于字节流或者字符流的进行操作，而NIO 是基于`缓冲区`和`通道`进行操作的，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中

2. Selector：选择器用于监听多个通道的事件（如，连接打开，数据到达），因此，单个线程可以监听多个数据通道，极大提升了单机的并发能力

   当 Channel 上的 IO 事件未到达时，线程会在 select 方法被挂起，让出 CPU 资源，直到监听到 Channel 有 IO 事件发生，才会进行相应的处理

- **NIO和BIO有什么区别？**

1. NIO是以`块`的方式处理数据，BIO是以`字节流或者字符流`的形式去处理数据。 
2. NIO是通过`缓存区和通道`的方式处理数据，BIO是通过`InputStream和OutputStream流`的方式处理数据。 
3. NIO的通道是双向的，BIO流的方向只能是单向的。
4. NIO采用的多路复用的同步非阻塞IO模型，BIO采用的是普通的同步阻塞IO模型。
5. NIO的效率比BIO要高，NIO适用于网络IO，BIO适用于文件IO。

**NIO如何实现了同步非阻塞？**

通过 Selector 和 Channel 来进行实现，一个线程使用一个 Selector 监听多个 Channel 上的 IO 事件，通过配置监听的通道Channel为非阻塞，那么当Channel上的IO事件还未到达时，线程会在select方法被挂起，让出CPU资源。直到监听到Channel有IO事件发生时，才会进行相应的响应和处理。



使用 NIO 通信的流程图如下：

![1705479910470](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705479910470.png)











## 硬件级别可见性问题面试实战

这里为什么要了解一下可见性的底层原理呢？

因为对于可见性这块的内容，他并不是软件层面上的问题，而是硬件层面的问题，是底层的一些机制导致了可见性的问题，**了解了底层的相关内容之后，我们的知识会更容易形成一个闭环，而不仅仅是停留于软件层面，对下层一无所知！**

所以接下来聊一聊底层中到底是什么原因导致了不同线程之间出现这个可见性的问题

### 可见性硬件级别造成原因

首先，每一个处理器都有自己的寄存器，而线程对变量的读操作都是针对写缓冲进行的，因此这个可见性问题与 `寄存器` 和 `写缓冲` 这两个硬件组件是有关联的

这里分别说一下寄存器和写缓冲 `如何导致了可见性的问题`：

- 多个处理器都在运行各自的线程的时候，`如果其中一个处理器中的线程将某一个变量更新后的值放在寄存器中`，那么其他处理器中的线程是没有办法看到这个更新后的值的，因为这个寄存器是各个处理器私有的，因此，寄存器会导致可见性的问题

- 处理器运行的线程，`对变量的写操作是针对写缓冲进行的`，之后才会刷到主内存中，因此如果一个线程更新了变量，如果仅仅写入到了写缓冲充，还没有刷到主内存或高速缓存中，那么其他处理器中的线程是无法感知到这个变量的修改的，此时，导致可见性的问题

  即使这个写缓冲的数据的更新也同步到了自己的主内存或高速缓存里，并且将这个更新通知给了其他的处理器，但是其他处理器可能把这个更新放到无效队列中，并没有更新自己的高速缓存，此时仍然会导致可见性的问题

如下这个图：

![1705573422897](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705573422897.png)



### MESI 协议

那么要实现多个处理器的共享数据的一致性，可以通过 MESI 协议来实现

根据具体底层硬件的不同，MESI 协议的具体实现也是不同的

这里说一种 MESI 协议的实现：通过将其他处理器高速缓存中 `更新后的数据` 拿到自己的高速缓存中更新一下，这样不同处理器之间的高速缓存中的数据就保持一致了，实现了可见性

在实现 MESI 协议的过程中，需要 `两个关键的机制` 来确保缓存的一致性：flush 和 refresh

- **flush**

将自己更新的值刷新到高速缓存里去，让其他处理器在后续可以通过一些机制从自己的高速缓存里读到更新后的值

并且还会给其他处理器发送一个 flush 消息，让其他处理器将对应的缓存行标记为无效，确保其他处理器不会读到这个变量的过时版本

- **refresh**

处理器中的线程在读取一个变量的值的时候，如果发现其他处理器的线程更新了变量的值，必须从其他处理器的高速缓存（或者是主内存）里，读取这个最新的值，更新到自己的高速缓存中



**因此，在底层通过 MESI 协议、flush 处理器缓存和 refresh 处理器缓存来保证可见性的**



总结一下就是，flush 是强制将更新后的数据从写缓冲器中刷新到高速缓存中去；refresh 是去感知到其他处理器更新了变量，主动从主内存或其他处理器的高速缓存中加载最新数据



**那么举个例子，对于 `volatile` 变量来说：**

```java
volatile boolean flag = true;
```

当写 volatile 变量时，就会通过执行一个内存屏障，在底层会触发flush处理器缓存的操作，把数据刷到主内存中

当读 volatile 变量时，也会通过执行一个内存屏障，在底层触发refresh操作，从主内存中，读取最新的值



### 指令重排

指令重排的内容我们可以来了解一下，什么时候会发生指令重排

指令重排指的是我们写好的代码，在真正执行的时候，执行顺序可能会被重排序，如果重排序之后，在多线程的执行环境下，可能就会出现一些问题

**什么时候会发生指令重排呢？**

- 编译期间

Java 中有两种编译器，一种是静态编译器（javac），另一种是动态编译器（JIT）

javac 负责把 .java 文件中的源代码编译为 .class 文件中的字节码，这个一般是程序写好之后进行编译的

JIT 是 JVM 的一部分，负责把 .class 文件中的字节码编译为 JVM 所在操作系统支持的机器码，一般在程序运行过程中进行编译

那么在编译期间，可能编译器为了提高代码的执行效率，会对指令进行重排，JIT 对指令重排还是比较多的

- 处理器执行顺序

编译器编译好的指令，到真正处理器执行的时候，可能还会调整顺序



**指令重排有什么规则约束呢？**

上边讲过了一个 happens-before 原则，它定义了一些规则，只要符合 happens-before 中的规则的都不会进行指令重排

就比如说，下边代码的第三行不可能重排到上边，因为它的执行结果依赖了上边两行的执行结果，因此不会重排，但是前两行可能会重排：

```java
int a = 1;
int b = 2;
int c = a + b;
```





### 经典指令重排案例

这里说一个在 JIT 动态编译时，经典的指令重排现象，`双端检锁` 时发生指令重排可能导致的错误

首先，双端检锁是用于构造单例对象的，如下：

```java
public class Singleton {
    private static Singleton INSTANCE;

    private Singleton() {

    }

    public static Singleton getInstance() {
        //第一次校验单例对象是否为空
        if (INSTANCE == null) {
            //同步代码块
            synchronized (Singleton.class) {
                //第二次校验单例对象是否为空
                 if (INSTANCE == null) {
                    INSTANCE = new Singleton();
                 }
            }
        }
        return INSTANCE;
    }

    public static void main(String[] args) {
        for (int i = 0; i < 20; i++) {
            new Thread(() -> System.out.println(Singleton.getInstance().hashCode())).start();
        }
    }
}
```

> 从字节码层面来看上述代码

```bash
 0 getstatic #2 <com/qy/nettychat/Volatile/Demo1.INSTANCE : Lcom/qy/nettychat/Volatile/Demo1;>
 3 ifnonnull 37 (+34)
 6 ldc #3 <com/qy/nettychat/Volatile/Demo1>
 8 dup
 9 astore_0
10 monitorenter
11 getstatic #2 <com/qy/nettychat/Volatile/Demo1.INSTANCE : Lcom/qy/nettychat/Volatile/Demo1;>
14 ifnonnull 27 (+13)
17 new #3 <com/qy/nettychat/Volatile/Demo1>
20 dup
21 invokespecial #4 <com/qy/nettychat/Volatile/Demo1.<init> : ()V>
24 putstatic #2 <com/qy/nettychat/Volatile/Demo1.INSTANCE : Lcom/qy/nettychat/Volatile/Demo1;>
27 aload_0
28 monitorexit
29 goto 37 (+8)
32 astore_1
33 aload_0
34 monitorexit
35 aload_1
36 athrow
37 getstatic #2 <com/qy/nettychat/Volatile/Demo1.INSTANCE : Lcom/qy/nettychat/Volatile/Demo1;>
40 areturn
```



> 其中双端检锁（DCL）部分字节码如下

```java
17 new #3 <com/qy/nettychat/Volatile/Demo1>
20 dup
21 invokespecial #4 <com/qy/nettychat/Volatile/Demo1.<init> : ()V>
24 putstatic #2 <com/qy/nettychat/Volatile/Demo1.INSTANCE : Lcom/qy/nettychat/Volatile/Demo1;>
```

- new 创建一个对象，并将其引用压入栈顶
- dup 复制栈顶数值并将值压入栈顶
- invokespecial 调用Demo1的初始化方法
- putstatic 将该引用赋值给静态变量 INSTANCE

在单线程下 `putstatic` 和 `invokespecial` 进行指令重排，可以提高效率；在多线程下，指令重排可能会出现意想不到的结果

- 单线程情况下，JVM 在执行字节码时，会出现指令重排情况：在执行完`dup`指令之后，为了加快程序执行效率，跳过构造方法的指令(`invokespecial`) ，直接执行`putstatic`指令，然后再将操作数栈上剩下的引用来执行`invokespecial`。单线程情况下JVM任何打乱`invokespecial`和`putstatic`执行顺序并不会影响程序执行的正确性。
- 多线程情况下，如果发生上述指令重排，此时第二个线程执行`getInstance`会执行到`if(INSTANCE==NULL)`，**此时会拿到一个尚未初始化完成的对象，那么使用未初始化完成的对象时可能会发生错误。**


示例图如下：

![1706948521052](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1706948521052.png)


### 指令乱序机制

> 这个内容可以作为扩展了解！

指令乱序机制是现代处理器中用于提升性能的一种技术

指令乱序的意思时，`处理器` 不会按照程序中指令的顺序来严格顺序执行，而是会动态地调整指令地顺序，哪些指令先就绪，就先执行哪些指令，之后将每个指令的执行结果放到一个 `重排序处理器` 中，重排序处理器把各个指令的结果按照代码顺序应用到主内存或者写缓冲器里

指令乱序机制可能造成数据一致性的问题，因此处理器提供了 `内存屏障` 和 `同步原语（volatile、synchronized 等）` 来保证在需要的时候，指令的执行顺序可以被保证同步，防止指令乱序执行

![1705633847127](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705633847127.png)











### 高速缓存和写缓冲器的`内存重排序`造成的视觉假象

这里讲一下高速缓存和写缓冲器的 `内存重排序` 造成的视觉假象：

处理器会将数据写入到写缓冲器中，这个过程就是 store；从高速缓存里读数据，这个过程就是 load，对于处理器来说，它的重排处理器是按照顺序来 load 和 stroe 的，但是如果在写缓冲器中发生了内存层面的指令重排序，就会导致其他处理器认为当前重排序后的指令顺序发生了变化

举个例子：比如现在有两个写操作 W1 和 W2，处理器先执行了 W1 再执行了 W2，写入到了 `写缓冲器` 中，而写缓冲可能为了提升性能，先将 W2 操作的数据写入到高速缓存中，再将 W1 操作的数据写入到高速缓存中，这样 W2 操作的结果先写入到 `高速缓存` 中后，会 `先被其他处理器感知到`，那么其他处理器就会误认为 W2 操作是先于 W1 操作执行的，这个就是 `重排序造成的视觉假象`！

整个过程如下图，处理器 1 先执行 W1 再执行 W2，结果写缓冲器重排序后，将 W2 操作排在了前边：

![1705639547298](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705639547298.png)



这个内存重排序，有4种可能性： 

1.  LoadLoad重排序：一个处理器先执行一个L1读操作，再执行一个L2读操作；但是另外一个处理器看到的是先L2再L1
2.  StoreStore重排序：一个处理器先执行一个W1写操作，再执行一个W2写操作；但是另外一个处理器看到的是先W2再W1
3.  LoadStore重排序：一个处理器先执行一个L1读操作，再执行一个W2写操作；但是另外一个处理器看到的是先W2再L1
4.  StoreLoad重排序：一个处理器先执行一个W1写操作，再执行一个L2读操作；但是另外一个处理器看到的是先L2再W1



**接下来举一个具体的例子：**

对于下边的代码，在硬件层面上可能多个线程并行地调度到不同地处理器上执行，通过并行执行来提高性能，假如 `处理器 0` 和 `处理器 1` 同时来执行下边代码，如果处理器 0 的写缓冲器为了提高性能，进行了 `内存重排序`，先将 `loaded = true` 的结果更新到 `高速缓存`，再去更新 `loadConfig()` 的执行结果，那么如果处理器 0 刚更新完 loaded 的值，还没来得及更新 loadConfig 的值，此时 `resource` 还是 null，处理器 1 发现 loaded 为 true 了，直接调用 `resource.execute()` 方法，那么就会出现空指针的问题，`这就是内存重排序可能会带来的问题`：

```java
Config config = null;
Boolean loaded = false;

// 处理器 0
resource = loadConfig();
loaded = true;

// 处理器 1
while (!loaded) {
  try {
    Thread.sleep(1000);
  } catch (Exception e) {
    ...
  }
}
resource.execute();
```



**为了容易理解 `指令重排如何造成空指针问题`，我这里也画了一张时间线图：**

![1705641001102](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1705641001102.png)







### synchronized 对原子性、可见性和有序性的保证

> **学习内存屏障注意事项：**
>
> 对于内存屏障的内容不要太抠细节，因为对于不同的底层硬件，内存屏障的实现也是不同的，所以在学习的时候，有些文章中是加这个屏障，而另外一些文章又是加其他的屏障，这个都无所谓的，我们只 `需要学习到内存屏障是如何保证可见性和有序性的就可以了`



**这里主要聊一聊 synchronized 底层到底是如何保证原子性、可见性和有序性的**

- `原子性`的保证

**这里保证的原子性就是当一个线程执行到 synchronized 的同步代码块中时，不会在执行过程中被其他线程中断**

synchronized 是基于两个 JVM 指令来实现的：`monitorenter` 和 `monitorexit`

那么在这两个 JVM 指令中的代码就是被上了锁的，这一段代码就只有当前加锁的线程可以执行，从而保证原子性

- `可见性`的保证

通过添加一些 `内存屏障` 来保证，在 synchronized 修饰的同步代码块中所做的 `所有变量写操作`，都会在释放锁的时候，强制执行 `flush 操作`，来保证可以让其他处理器中的线程可以感知到变量的更新

而在进入 synchronized 的同步代码块时，会先执行 `refresh 操作`，来保证读取到最新变量

- `有序性`的保证

也是通过加各种 `内存屏障` 来保证的，避免指令重排的问题



**接下来看一下，在 synchronized 同步代码块中，到底会添加哪些 `内存屏障`：**

```java
int b = 0;
int c = 0;
synchronized (this) {  --> monitorenter
  --> Load 内存屏障
  --> Acquire 内存屏障
  
  int a = b;
  c = 1;
   
  --> Release 内存屏障
} --> monitorexit
--> Store 内存屏障
```



这里可能大家对 `Acquire` 和 `Release` 内存屏障有点陌生，但是一定知道 LoadLoad、LoadStore、StoreStore、StoreLoad 屏障，下边说一下他们的关系：

- `Acquire 屏障 = LoadLoad + LoadStore`
  - Acquire 屏障确保一个线程在执行到屏障之后的内存操作之前，能看到其他线程在屏障之前的所有内存操作的结果
- `Release 屏障 = LoadStore + StoreStore`
  - Release 屏障用于确保一个线程在执行到屏障之后的内存操作之前，其他线程能看到该线程在屏障之前的所有内存操作的结果



**那么对于上边 synchronized 的同步代码块，这里解释一下每个屏障的作用：**

1. 在 `monitorenter` 指令后，添加 `Load 屏障`，执行 refresh 操作，可以去将其他处理器中修改过的最新数据加载到自己的高速缓存种
2. Load 屏障之后，添加了 `Acquire 屏障`，可以保证当前线程可以读到 Acquire 屏障前所有内存操作的结果
3. 在 `monitorexit` 指令前，添加 `Release 屏障`，保证一个线程在执行到屏障之后的内存操作之前，其他线程能看到该线程在屏障之前的所有内存操作的结果
4. 在 `monitorexit` 指令后，添加了 `Store 屏障`，对自己在同步代码块中修改的变量执行 flush 操作，刷新到高速缓存或者=主内存中，让其他处理器中的线程可以感知到数据的变化

因此通过 Acquire、Release、Load、Store 屏障来保证了有序性



**一句话总结**

简单总结一下就是，在 synchronized 代码块开始时，加内存屏障，保证可以感知到屏障前所有的内存操作变化，在 synchronized 结束后，加一个内存屏障，保证可以将内存操作的更新情况立即刷新到高速缓存或者主内存中，可以让其他线程感知到！





### volatile 对可见性、有序性的保证

volatile 是不保证原子性的，只保证了可见性和有序性，底层就是基于各种 `内存屏障` 来实现的

使用 volatile 关键字之后，加入的内存屏障如下：

```java
volatile boolean flag = false;

--> Release 屏障
flag = true;  // volatile 写
--> Store 屏障

--> Load 屏障
if (flag) { // volatile 读
	--> Acquire 屏障
	// ... 
}
```



主要是在 volatile 写操作和读操作前后都添加内存屏障来保证：

- `在 volatile 写操作之前`，加入了 Release 屏障，保证了 volatile 写和 Release 屏障之前的任何读写操作不会发生指令重排
- `在 volatile 写操作之后`，加入了 Store 屏障，保证了写完数据之后，立马会执行 flush 操作，让其他处理器的线程感知到数据的更新
- `在 volatile 读操作之前`，加入了 Load 屏障，保证可以读取到这个变量的最新数据，如果这个变量被其他处理器中的线程修改了，必须从其他处理器的高速缓存或者主内存中加载到自己本地高速缓存里，保证读到的是最新数据
- `在 volatile 读操作之后`，加入了 Acquire 屏障，禁止 `volatile 读操作之后的任何读写操作` 和 `volatile 读操作` 发生指令重排

