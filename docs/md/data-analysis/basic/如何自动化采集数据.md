# 04-如何自动化采集数据

## 0 前言

上文讲咋对用户画像建模，而建模前要数据采集。有多少数据源，多少数据量，数据质量，将决定挖掘产出的成果。

如量化投资，基于大数据预测未来股票波动，根据这个预测结果买卖。你当前能够拿到以往股票的所有历史数据，是否可以根据这些数据做出一个预测率高的数据分析系统呢？

如只有股票历史数据，仍无法理解股票为什么会产生大幅波动。如当时可能爆发疫情或某地发生战争。这些重大社会事件对股票影响也巨大。

因此要考虑，一个数据走势是由多维影响。要通过**多源的数据采集**，收集尽可能多**数据维度**，同时保证数据的质量，才能得到高质量的数据挖掘结果。

数据采集角度，有哪些数据源？

## 1 数据源分类



![](https://my-img.javaedge.com.cn/javaedge-blog/2024/10/2e26981a785f7a6e2523f052cd38277e.jpeg)

### 开放数据源

一般针对行业的数据库。比如美国人口调查局开放了美国的人口信息、地区分布和教育情况数据。除了政府外，企业和高校也会开放相应的大数据，这方面北美相对来说做得好一些。国内，贵州做了不少大胆尝试，搭建了云平台，逐年开放了旅游、交通、商务等领域的数据量。

很多研究都是基于开放数据源，否则每年不会有那么多论文发表，大家需要相同数据集才能对比算法好坏。

### 爬虫

一般针对特定网站或 App。如想抓取指定网站数据，如购物网站的购物评价，就需要做特定的爬虫抓取。

### 传感器

它基本上采集的是物理信息。比如图像、视频、或者某个物体的速度、热度、压强等。

### 日志采集

这个是统计用户的操作。我们可以在前端进行埋点，在后端进行脚本收集、统计，来分析网站的访问情况，以及使用瓶颈等。

咋采集这些数据呢？

## 2 咋用开放数据源

可从两维考虑：

- 单位维度，如政府、企业、高校
- 行业维度，如交通、金融、能源等领域。国外的开放数据源比国内做得好一些，当然近些年国内的政府和高校做开放数据源的也越来越多。一方面服务社会，另一方面自己的影响力也会越来越大。

如下表列举单位维度的数据源：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/10/da6c227cf944dcd740e23ad833c85203.jpeg)

如想找某领域的数据源，如金融领域，基本可看政府、高校、企业是否有开放数据源。也可直接搜索金融开放数据源。

## 3 咋用爬虫做抓取

想要餐厅评价数据。注意版权，很多网站也有反爬。

最直接的用 Python 写爬虫：

1. 使用 Requests 爬取内容。可用 Requests 库来抓取网页信息。也就是 Python 的 HTTP 库，通过这个库爬取网页中的数据，非常方便
2. 使用 XPath 解析内容。XPath 是 XML Path 的缩写，也就是 XML 路径语言。它是一种用来确定 XML 文档中某部分位置的语言，在开发中经常用来当作小型查询语言。XPath 可以通过元素和属性进行位置索引
3. 使用 Pandas 保存数据。Pandas 是让数据分析工作变得更加简单的高级数据结构，用 Pandas 保存爬取的数据。最后通过 Pandas 再写入到 XLS 或 MySQL 等数据库

Python 爬虫利器还有 Selenium，PhantomJS，或者用 Puppteteer 这种无头模式。也可不编程抓取网页信息：

**[火车采集器](http://www.locoy.com/)**

老牌采集工具。它不仅可以做抓取工具，也可做数据清洗、数据分析、数据挖掘和可视化等工作。数据源适用于绝大部分的网页，网页中能看到的内容都可以通过采集规则进行抓取。

**[八爪鱼](http://www.bazhuayu.com/)**

知名采集工具：

- 免费的采集模板：内容采集规则，包括了电商类、生活服务类、社交媒体类和论坛类的网站都可以采集，用起来非常方便。当然你也可以自己来自定义任务。
- 云采集（付费）：配置好采集任务，就可以交给八爪鱼的云端进行采集。八爪鱼一共有 5000 台服务器，通过云端多节点并发采集，采集速度远远超过本地采集。此外还可以自动切换多个 IP，避免 IP 被封，影响采集。

免费的采集模板实际上就是那什么是云采集呢？就是当你配置好采集任务，就可以交给八爪鱼的云端进行采集。八爪鱼一共有 5000 台服务器，通过云端多节点并发采集，采集速度远远超过本地采集。还可自动切换多个 IP，避免 IP 被封，影响采集。

**很多时候自动切换 IP 以及云采集才是自动化采集的关键**。

**[集搜客](http://www.gooseeker.com/)**

这个工具的特点是完全可视化操作，无需编程。整个采集过程也是所见即所得，抓取结果信息、错误信息等都反应在软件中。相比于八爪鱼来说，集搜客没有流程的概念，用户只需要关注抓取什么数据，而流程细节完全交给集搜客来处理。

但是集搜客的缺点是没有云采集功能，所有爬虫都是在用户自己电脑上跑的。

## 4 咋用日志采集工具

传感器采集基本上是基于特定的设备，将设备采集的信息进行收集即可，这里我们就不重点讲解了。

### 为啥做日志采集？

日志采集最大的作用，就是通过分析用户访问情况，提升系统的性能，从而提高系统承载量。及时发现系统承载瓶颈，也可以方便技术人员基于用户实际的访问情况进行优化。

日志都包括哪些呢，又该如何对日志进行采集呢？

日志就是日记，记录了用户访问网站全过程：哪些人在啥时间，通过啥渠道（如搜索引擎、网址输入）来过，都执行哪些操作；系统是否产生错误；甚至包括用户IP、HTTP请求时间，用户代理等。这些日志数据可被写在一个日志文件，也可分成不同日志文件，如访问日志、错误日志等。

### 日志采集形式

#### Web服务器采集

例如 httpd、Nginx、Tomcat 都自带日志记录功能。同时很多互联网企业都有自己的海量数据采集工具，多用于系统日志采集，如 Hadoop 的 Chukwa、Cloudera 的 Flume、Facebook 的 Scribe 等，这些工具均采用分布式架构，能够满足每秒数百 MB 的日志数据采集和传输需求。

#### 自定义采集用户行为

如用 js 监听用户的行为、AJAX 异步请求后台记录日志等。

### 埋点

日志采集的关键步骤，啥是埋点？

**埋点就是在有需要的位置采集相应的信息，进行上报**。比如某页面的访问情况，包括用户信息、设备信息；或者用户在页面上的操作行为，包括时间长短等。这就是埋点，每一个埋点就像一台摄像头，采集用户行为数据，将数据进行多维度的交叉分析，可真实还原出用户使用场景，和用户使用需求。

### 咋进行埋点？

埋点就是在你需要统计数据的地方植入统计代码，当然植入代码可以自己写，也可以使用第三方统计工具。我之前讲到“不重复造轮子”的原则，一般来说需要自己写的代码，一般是主营核心业务，对于埋点这类监测性的工具，市场上已经比较成熟，这里推荐你使用第三方的工具，比如友盟、Google Analysis、Talkingdata 等。他们都是采用前端埋点的方式，然后在第三方工具里就可以看到用户的行为数据。但如果我们想要看到更深层的用户操作行为，就需要进行自定义埋点。

### 小结

日志采集有助了解用户操作数据，适用于运维监控、安全审计、业务数据分析等场景。一般 Web 服务器自带日志功能，也可用 Flume 从不同服务器集群中采集、汇总和传输大容量的日志数据。也可用第三方统计工具或自定义埋点得到想要的统计内容。

## 5 总结

数据采集是数据分析关键，很多时候想到 Python 网络爬虫，实际上数据采集方法、渠道很广，有些可直接用开放数据源，如想获取比特币历史的价格及交易数据，可以直接从 Kaggle 上下载，无需自己爬取。

另一方面根据需求，需要采集数据也不同，如交通行业，数据采集会和摄像头或者测速仪有关。对于运维人员，日志采集和分析则是关键。所以我们需要针对特定的业务场景，选择适合采集工具。

如你想预测比特币的未来走势，都需要哪些维度的数据源呢？怎样收集到它们？