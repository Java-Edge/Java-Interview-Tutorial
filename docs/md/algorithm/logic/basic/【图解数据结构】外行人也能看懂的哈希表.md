# 【图解数据结构】外行人也能看懂的哈希表

输入一个错误的英文单词，它就会提示“拼写错误”。这个单词拼写检查功能，虽然很小但却非常实用。是如何实现的呢？

# 1 什么是散列？

散列表，Hash Table，用数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。

假如有89名候选人参加大选。为了方便记录投票，每个候选人胸前会贴上自己的参赛号码。这89名选手的编号依次是1到89。
通过编号快速找到对应的选手信息。你怎么做？

可以把这89人的编号跟数组下标对应，查询编号x的人时，只需将下标为x的数组元素取出，时间复杂度就是O(1)。看来按编号查对应人信息，效率很高。

这就是散列，编号是自然数，并且与数组的下标一一映射，所以利用数组支持根据下标随机访问时间复杂度是O(1)，即可实现快速查找编号对应的人信息。

假设编号不能设置这么简单，要加上州名、职位等更详细信息，所以编号规则稍微修改，用6位数字表示。比如051167，其中，前两位05表示州，中间两位11表示职位，最后两位还是原来的编号1到89。

> 此时如何存储选手信息，才支持通过编号来快速查找人信息？

可以截取编号的后两位作为数组下标，来存取候选人信息数据。当通过编号查询人信息时，同样取编号后两位，作为数组下标读取数组数据。

这就是散列。候选人编号叫作键（key）或关键字，以标识一个候选人。把参赛编号转化为数组下标的映射方法就叫作散列函数（或“Hash函数”“哈希函数”），而散列函数计算得到的值就叫作散列值（或“Hash值”“哈希值”）。

散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是O(1)的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。

## 1.1 装载因子（load factor）

表示空位的多少：

```bash
散列表的装载因子=填入表中的元素个数/散列表的长度
```

- 装载因子越大，说明空闲位置越少，哈希冲突概率越大，插入过程要多次寻址或拉长链，查找也会因此变得很慢。
- 太小，会导致内存浪费严重。

## 1.2 哈希表碰撞攻击

有些攻击者会构造数据，使得所有数据经过hash函数后同槽。若使用的链表法，这时哈希表就会退化为链表，查询时间复杂度从O(1)急剧退化为O(n)。

若哈希表有10w数据，退化后的hash表查询效率就下降10万倍。若之前运行100次查询需0.1s，则现在需1w s。这就可能消耗大量CPU或线程资源，导致系统无法响应其他请求，即拒绝服务攻击（DoS）。

# 2 hash函数

即hash(key)，其中key表示元素的K值，hash(key)的值表示经过散列函数计算得到的hash值。

若编号就是数组下标，所以hash(key)就等于key。改造后的例子，写成hash函数稍微有点复杂。我用伪代码将它写成函数就是下面这样：

```java
int hash(String key) {
  // 获取后两位字符
  string lastTwoChars = key.substr(length-2, length);
  // 将后两位字符转换为整数
  int hashValue = convert lastTwoChas to int-type;
  return hashValue;
}
```

但现实都是复杂的，若候选人编号是随机生成的N位数或a到z之间的字符串，散列函数该如何实现？

##  2.1 要求

- 散列函数计算得到的散列值是个非负整数
  因为数组下标从0开始
- 若key1 = key2，则hash(key1) == hash(key2)
- 若key1 ≠ key2，则hash(key1) ≠ hash(key2)
  此要求看起来合理，但实际上几乎找不到一个不同key对应散列值都不同的散列函数，即使如MD5、SHA、CRC。而且数组存储空间也是有限的，散列冲突概率就更大了。
- 不能太复杂
  过度复杂会消耗大量计算时间，影响hash表性能
- hash函数生成的值要尽可能随机并且均匀分布
  避免或最小化哈希冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会数据倾斜

## 2.2 案例

处理手机号码，因为手机号码前几位重复的可能性很大，但后面几位就比较随机，可以取手机号后四位作为散列值。这种设计方法称为“数据分析法”。

单词拼写检查功能的hash函数可考虑：

- 将单词中每个字母的ASCll码值“进位”相加
- 再跟哈希表的size求余、取模，作为散列值

比如，英文单词java，我们转化出来的散列值就是下面这样：

```bash
hash("java")=(("j" - "a") * 26*26*26 + ("a" - "a")*26*26 + ("v" - "a")*26+ ("a"-"a")) / 78978
```

还有很多设计方法，比如直接寻址法、平方取中法、折叠法、随机数法等。hash函数设计的好坏，决定了哈希表冲突的概率大小，也直接决定了哈希表的性能。


无论设计的多么优秀，还是得考虑如何解决散列冲突问题。

# 3 散列冲突

## 3.1 开放寻址法

若出现hash冲突，就重新探测一个空闲位置，将其插入。
最简单的就是

### 3.1.1 线性探测（Linear Probing）

当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。如ThreadLocalMap。

#### 案例

- 黄块
  空闲位置
- 橙块
  已存储数据
  ![](https://img-blog.csdnimg.cn/df1181f8eb684424a27182f12abf4be6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)

散列表的大小10，在元素x插入散列表之前，已有6个元素在散列表。
x经过Hash算法后，被hash到下标7处，但该位置已有数据，所以hash冲突。
顺序再往后一个个找，看有无空闲位置，遍历到尾部都没有空闲位置，就再从表头开始找，直到找到空闲位置2插入。

#### 查找元素

类似插入过程。通过hash函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素：

- 若相等
  则为目标元素
- 否则
  继续顺序往后查找

若遍历到数组中的空闲位置，还没找到，说明目标元素不在散列表。
![](https://img-blog.csdnimg.cn/54eb69cf00b244aab1cb15ca82c41952.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)

线性探测法的散列表，删除操作不能单纯地把要删除的元素置null。这是为什么呢？
查找时，一旦通过线性探测方法，找到一个空闲位置，即可认定散列表不存在该数据。
但若该空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。

可以将删除的元素，特殊标记为deleted。当线性探测查找时，遇到deleted空间，并不是停下来，而是继续往下探测。
![](https://img-blog.csdnimg.cn/03b59bac1bec492abb846d8c2e17973a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 缺陷

线性探测法其实存在很大问题。当散列表中数据越多，hash冲突可能性越大，空闲位越少，线性探测时间越久。
极端情况下，可能需探测整个散列表，所以最坏时间复杂度O(n)。

删除和查找时，也可能线性探测整张散列表，才能找到要查找或删除的数据。

### 二次探测（Quadratic probing）

### 双重散列（Double hashing）

类似线性探测，线性探测每次探测的步长是1，那它探测的下标序列就是

- hash(key)+0
- hash(key)+1
- hash(key)+2
- 。。。

二次探测探测的步长就变成了原来的“二次方”，即探测的下标序列是：

- hash(key)+0
- hash(key)+12
- hash(key)+22
- ……

双重散列就是不仅要使用一个散列函数，而使用一组散列函数：
先用第一个散列函数，如果计算得到的存储位置已被占用，再用第二个散列函数，直到找到空闲位。

不管哪种探测方法，当散列表中空闲位置不多时，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。

## 优点

- 不像链表法，需要拉很多链表。数据都存在数组中，可有效地利用CPU缓存加快查询速度
- 序列化也更简单。链表法包含指针，序列化比较麻烦。

## 缺点

- 删除数据时，需特殊标记已删除的数据
- 所有的数据都存储在一个数组中，冲突的代价更高

所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。

当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是Java中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。

## 3.2 链表法

相比开放寻址法简单。
散列表中，每个“桶（bucket）”或“槽（slot）”对应一条链表：散列值相同的元素放到相同槽位对应的链表。
![](https://img-blog.csdnimg.cn/81b31ea44f9d41a2b6ef224b87b54a7b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)

- 插入时，只需通过hash函数计算对应槽位，将其插入到对应链表，时间复杂度O(1)。

### 查找、删除

同样通过hash函数计算出对应槽，然后遍历链表查找或删除。
时间复杂度都和链表长度k成正比，即O(k)，所以查询的效率并非简单地O(1)，若hash函数设计得不好或loadFactor过高，都可能导致散列冲突发生的概率升高，查询效率下降。

对于散列均匀的hash函数，理论上：

```java
k=n/m
```

其中n表示散列中数据的个数，m表示散列表中“槽”的个数。

## 优点

- 对内存的利用率比开放寻址法要高
  因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。这也是链表优于数组的地方。
- 对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于1的情况。接近1时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。

## 缺点

链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对CPU缓存是不友好的，这方面对于执行效率也有一定的影响。

存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4个字节或者8个字节），那链表中指针的内存消耗在大对象面前就可以忽略了。

对链表法稍加改造，可以实现一个更加高效的散列表。那就是，我们将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。
![](https://img-blog.csdnimg.cn/c41922bf79c74c97aaa0220a3be6a6cb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)
基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

# 4 扩容

- 没有频繁插入和删除的静态数据集合，即使实习生也能轻松根据数据特点，设计出优秀的hash函数
- 而动态hash表，数据频繁变动，无法预估数据个数，所以无法预申请一个足够的hash表。随数据越多，装载因子就会慢慢变大。当装载因子大到一定程度后，哈希冲突就会令程序窒息，此时资深的程序员们该咋办呢？

针对hash表，当 **loadFactor** 过大，可进行动态扩容，新申请更大的hash表，将数据迁移至新hash表。
假设每次扩容，申请一个原来hash表两倍size的。若原hash表装载因子0.8，则扩容后的新hash表装载因子就降为原来的一半0.4了。

但hash表的扩容，数据搬移操作要复杂很多。因为哈希表的大小变了，数据的存储位置也变了，需通过hash函数重新计算每个数据的存储位置。

原来hash表的21存储在0位，迁移新hash表后存储在7位。
![](https://img-blog.csdnimg.cn/be4b95c33ae14ae992c34b89b8bf5a90.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)

> 动态扩容的散列表，插入操作的时间复杂度是多少呢？

插入一个数据：

- 最好无需扩容，时间复杂度O(1)
- 最坏情况，hash表loadFactor过高，开启扩容新申请内存空间，重新计算哈希位置并迁移数据，时间复杂度O(n)。用摊还分析法，均摊情况下，时间复杂度接近最好情况，就是O(1)。

动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。
如果对空间消耗非常敏感，可以在装载因子小于某个值之后，启动动态缩容。
如果更在意执行效率，能够容忍多消耗一点内存空间，就不用费劲缩容。

### 避免低效扩容

大部分情况下，动态扩容的hash表插入一个数据都很快，但特殊情况下，当装载因子达阈值，需先扩容，再插数据。这时，插入数据就会变得很慢！
若hash表当前大小为1G，想扩容为原来2倍，就需对1G数据重新计算哈希值并从原hash表搬移到新表，听着都耗时！
所以这时，“一次性”扩容机制就不合适了。

为避免一次性扩容耗时过多，可将扩容操作穿插在插入操作的过程中分批完成。当装载因子达阈值后，只申请新空间，但并不将老数据搬移到新hash表。

当有新数据插入，将新数据插入新hash表中，并从老原hash表拿出一个数据放入新hash表。
每次插入一个数据到散列表，重复上面过程。
经过多次插入操作之后，原hash表的数据就一点点都迁移至新hash表。这就不会一次性数据搬移，插入操作就都变得很快了。
![](https://img-blog.csdnimg.cn/293efbb683f44f71b774ec45a7562043.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_SmF2YUVkZ2U=,size_20,color_FFFFFF,t_70,g_se,x_16)
这期间的查询操作怎么做？
为兼容新、老hash表数据，先查新hash表，没找到再去原hash表查找。

通过这样的均摊，将一次性扩容代价，均摊到多次插入操作，解决一次性扩容耗时过多问题。这时任何情况下，插入一个数据的时间复杂度都是O(1)。

## 应用

### 强大的 HashMap

#### 初始大小

默认16，可设，如事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，大大提高HashMap性能。

#### 装载因子和动态扩容

默认0.75，当HashMap中元素个数超过0.75*capacity（capacity表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。

#### 散列冲突解决方法

链表法解决冲突。即使负载因子和散列函数设计得再合理，也免不了拉链过长情况，一旦出现严重影响HashMap性能。

于是，在JDK1.8版本中，为了对HashMap做进一步优化，我们引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树。我们可以利用红黑树快速增删改查的特点，提高HashMap的性能。当红黑树结点个数少于8个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。

#### 散列函数

不复杂，追求简单高效、分布均匀。

```java
int hash(Object key) {
    int h = key.hashCode()；
    return (h ^ (h >>> 16)) & (capitity -1); //capicity表示散列表的大小
}
```

其中，hashCode()返回的是Java对象的hash code。比如String类型的对象的hashCode()就是下面这样：

```java
public int hashCode() {
  int var1 = this.hash;
  if(var1 == 0 && this.value.length > 0) {
    char[] var2 = this.value;
    for(int var3 = 0; var3 < this.value.length; ++var3) {
      var1 = 31 * var1 + var2[var3];
    }
    this.hash = var1;
  }
  return var1;
}
```

## 单词拼写检查功能是如何实现的？

常用英文单词20万个，假设单词平均长度10个字母，平均一个单词占用10字节，那20万英文单词大约占2MB存储空间，这完全可以放在内存。所以我们可以用散列表来存储整个英文单词词典。

当用户输入某个英文单词时，拿用户输入的单词去散列表中查找：

- 查到，则说明拼写正确
- 没有查到，则说明拼写可能有误，给予提示

这就能轻松实现快速判断是否存在拼写错误。