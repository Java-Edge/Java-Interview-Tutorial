# 小游戏的大促实践

# 大促游戏系统设计

## 1 游戏与大促

### 1.1 大促游戏选择

大促筹备阶段，运营会根据大促时间表，在游戏管理平台设置游戏活动开始、结束时间、奖池及页面素材。待大促进行时，主持人引导用户打开 APP 并进入小游戏页面。

运营会根据大促计划，从多款小游戏中选择几款参与到直播大促。通过游戏，运营可发放 金币，吸引用户在 APP 下单购买商品。

### 1.2 游戏

类似摇一摇，用户摇动次数越多，得到金币的概率越大。三阶段的游戏页面：

**游戏预热阶段**页面。游戏开始前，用户进入页面后，可见金币池的大小和游戏开始的倒计时，也可以将页面链接通过第三方或发消息分享给好友，获得额外金币奖励。

**游戏过程页面**。该页面会不停掉落金币。用户需要在有限时间内摇动手机。摇动速度越快，得到金币的概率越大。

**游戏结果页面**。用户在当局游戏获得的金币数量会显示在这一页面。由于每局游戏会消耗一次机会，剩余游戏机会在此页面也有直观呈现，若用户还有机会，可以直接点击按钮，继续进行游戏。有时，当地运营人员还会配置一些抽奖机会，若用户抽中某项奖品，同样会在该页面显示。

## 2 技术方案

后端系统的挑战：

- 瞬时并发量大

  游戏开始时间统一，所有用户都在同一时间进入游戏，短时间内产生大量请求

- 游戏时间短

  整场游戏环节一般持续 5 min，每局游戏通常在10s~30s

- 并发扣减金币池

  所有用户共享同一个游戏奖池，每一局游戏结束后都要并发扣减游戏奖池，后端系统容易因此出现单点问题，影响系统性能

因此，需支持高并发请求，支持水平扩容，并解决潜在的奖池单点问题。

### 2.1 架构设计

![](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jTzp84VHYicUsxiblfMlhRVTjps0jybqU6tAtKdcH8icdAOnXIwOUM7XiaA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

系统提供主要功能:

- 供运营进行大促活动配置
- 供终端用户玩游戏获得金币

因此，系统分成两端，即Admin管理端和用户端，分别面向运营和终端用户。

大促前，运营通过 Admin 端进行游戏相关配置。活动进行时，用户通过终端访问游戏页面，请求后端。最重要的两个请求：

- 游戏开始请求，业务逻辑是校验每个用户的机会是否足够，当前金币库存是否低于配置值等；
- 游戏结束请求的业务逻辑是计算用户得到的金币数、扣减金币库存、写排行榜、给用户发金币及获奖消息。

综上，系统整体架构分为三层：接入层、应用层和资源层。

- 接入层：负责接入用户请求，用户登录态校验及协议转换。
- 应用层：核心业务逻辑处理系统，包括活动配置加载、道具模块、机会模块、库存模块及很多微服务，如排行榜服务、拼团逻辑服务、获奖消息。
- 资源层：主要包含 MySQL、Codis 以及 Shopee 中台服务，如通知发送服务、金币发送服务、聊天服务。

### 2.2 高并发技术

#### 2.2.1 水平扩容

为支撑大流量，系统需支持水平扩容。只要支持水平扩容，就可通过增加机器数量提高系统吞吐量。系统支持水平扩容，就要求系统的接入层、应用层和存储层都支持水平扩容。

接入层、应用层可做成无状态服务，以支持水平扩容。但存储层支持水平扩容不易，需将存储数据均匀分布在不同存储节点。

系统采用 Codis 作为存储层，主要考虑到：

- 水平扩容：Codis 支持水平扩容，只要增加 Codis 集群的 Redis 实例数，即可做水平扩容
- 高性能读写数据：游戏中的用户机会、金币库存、排行榜等数据在游戏过程中会被频繁读写，因此需要能支持高性能读写的存储系统
- 数据无需持久化：游戏数据只在活动过程中使用，活动结束后无需保存

因此，Codis 作为存储层很合适。

但并不是说只要使用 Codis 存储层，就支持水平扩容，还要想办法将数据均匀分布在不同存储节点。最初设计游戏时并没注意到，以致系统在压测时出现瓶颈。后分析发现，Codis 集群有台 Redis 实例 CPU 使用率达到 100%，因为游戏的金币库存使用的 Codis key 是单点 key，超出单台 Redis 实例性能上限。流量较小时，这不是问题，但大流量时，会导致整个系统性能瓶颈。

游戏中，金币库存供所有用户共享，所有用户端在游戏结束时都会并发查询及扣减该库存值。当库存<指定值，游戏提前结束，以防止库存超发。因此，金币库存值的读写很频繁，且要求数值精确可靠。

使用单点key虽能保证金币库存值实时可靠，但带来性能瓶颈。解决该问题的方法是分桶，将一个金币库存拆分成多个分库存，不同用户去扣减不同分库存。这样就能将单点 key 拆分成多个 key，不同 key 的流量分散到不同 Redis 实例。因此存储层能承载 `QPS = N * 单台 Redis OPS`，N 为分库存个数。

分库存数量也可随流量增长而增长：

![图片](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jib977K2bh1C4PaGGNannt5RILR0Be73aP6b03jUYiaytHcz4IJucOoQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

使用分桶，会导致一种异常case——分库存扣减不均，部分用户因库存不足而提前结束游戏，但实际上另一分库仍有库存。这种情况不可能完全避免，大流量时，会出现大量扣减库存的请求，只要将用户流量尽量匀分到不同分库存，则可大大降低出现这种情况概率。

分桶，可有效提高系统吞吐量。而因此引入的分库存扣减不均的问题，在大流量情况下，也相对能接受。

#### 2.2.2 缓存

在游戏过程中，有很多数据是读多写少，甚至只读，如游戏配置、静态资源。这些数据适合缓存，可极大缓解DB压力，降低接口响应延时。

缓存漏斗模型：经过层层过滤后，透传到后面系统的流量越来越低。所以设计系统时，考虑数据读写频率，尽量将数据放到更接近用户的缓存。

![](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jpZfsZHJbkuenYxwJDFgJ4RlKuNpkrGibbKqSpCLv19tL30dBtDc3dng/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

每层系统都用缓存，如：

- Web 缓存
- 进程缓存
- Codis 缓存

对热点数据，需提前缓存，防止缓存不存在时，大流量瞬间冲击DB。Web静态数据则用 CDN 边缘缓存，以提高游戏加载速度。

系统后端用缓存时，需解决缓存更新：

- 流量较小，当缓存过期后，直接从DB获取数据
- 大流量时，会导致大量请求直接到DB，导致DB受到极大冲击，甚至导致雪崩

解决该问题，可使用锁：多个并发请求发现缓存过期，需查询DB时，先获取“更新缓存锁”，只有获取到“更新缓存锁”的请求才去查询DB，当查询DB完成且更新缓存成功后，释放“更新缓存锁”，而其他请求则进入等待状态，直到缓存被更新时，直接返回缓存：

![](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jatQYTypItE4AV88cu5kJaztxRYK8x4dicicNf7jztuibR5mhPiaG9VMZ0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

但该方案存在弊端：若网络抖动或后端DB异常，导致查询后端DB耗时过长，大量读请求因此被阻塞，最终占满内存。

曾在一次压测暴露出这一问题。当时，游戏服务内存在短时间内大幅增长，且接口延时变大。发现是缓存更新时DB异常，无法及时响应，导致大量请求被阻塞。

为解决这问题，采用**有限等待时间**，若在设定的等待时间内无法获取到最新缓存，则使用旧缓存。但这种解决方案有可能导致数据不一致。对于该系统，需查询数据库的数据都是游戏基本配置，而这些配置在游戏开始后修改频率低，所以有限等待时间的方案较符合业务场景。

### 2.3 异步

高并发时，为提高接口性能，有时会将一些耗时高，但无需阻塞主流程的操作放到MQ，减少在线系统的压力。同时使用另一个异步处理的服务，不断处理MQ的数据。本系统也采用该方案。

一次压测，发现游戏系统的游戏结束接口延时比其他接口大，而该接口主要用于接收用户摇动手机次数、计算用户获得金币数及给用户发放金币，是整个游戏中最重要的写接口，直接影响整个系统吞吐量。

经过性能分析及代码分析，游戏结束接口在以下两个功能上耗时最大，大约占接口总延时的 30%：

- 将用户游戏得分数写入排行榜
- 给用户发放金币及发送获奖通知

对用户场景进行分析并和产品经理讨论后，梳理了游戏结束接口中所有能异步处理的功能，并将这些功能异步处理：

- 用户游戏得分写入排行榜

  查看排行榜的入口较深，请求流量较低，且同时有大量用户正在玩游戏时，排行榜数据变化很快，用户并不需要看到榜单实时变化过程，因此只需在一定时间内输出最终排行榜数据

- 发放金币

  派发金币无需实时到账，这样的体验对用户可接受

- 发送获奖通知

  告知用户获得金币，无需实时通知

- 数据埋点上报

  上报用于离线分析的游戏数据。离线分析的数据无需实时上报

![](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jIkTc0Mlu3oibpxLh5EibAANQMuOFGknEpiaNCJ822j147nXiaLKOj76A4g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

异步处理要解决的问题：

- 不能丢消息

  因为异步处理无法实时感知消息处理结果，所以需保证消息不会丢失

- 幂等

  消息有可能会出现重复消费，需保证重复消息不会产生副作用

不能丢失消息这点，使用现有成熟MQ，如Kafka是能保证的。但存在MQ故障或容量满载，无法写入新消息，这时需提取日志，重新生成消息，发到异步处理服务。所以对MQ需加强监控，及时发现故障及数据补发。

对重复消费，可在每次游戏生成全局唯一ID，作为请求 ID 传给派奖系统，派奖系统根据请求 ID 作为唯一键，派奖前先查询当前请求 ID 是否曾派过奖，确保同一请求不会被重复处理。所以，引入异步处理会增加系统复杂度，但也能有效提高接口性能。

## 3 容量规划

每次大促前，需评估系统容量是否足够，是否能支持运营人员预估用户量。就得系统容量规划：

![图片](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2j2ZpCgnE6Lpx14hhwqFhjFoljmlE2y59egCxIKfHOyatUyQvmnmYRaQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

1. 单容器容量评估。该数据通过全链路压测获得。通过部署单容器容量，压测得到系统极限容量。单容器容量粒度精确到每个接口可承载 QPS
2. 将运营人员预估的 PCU（最大同时在线用户数）与 QPS 进行转换，计算得出系统需承载最大QPS
3. 计算部署的容器数量

- `容器数量 = 最大 QPS / 单容器容量`
- 预留部分机动资源，防止突发流量

1. 计算下游容量要求。如 Codis OPS、下游服务 QPS。

- `Codis OPS = 最大 QPS * 每请求 Codis 操作次数`

1. 计算得出容量后，按需求容量实际部署，包含业务容器数及下游中间件及游戏的需求部署。部署成功后，再做一次全链路压测，验证容量是否满足预估 QPS 需求。

## 4 立体监控

为能实时观察服务运行情况，及时发现异常，团队要对系统进行全方位、立体监控。包括接入层、应用层、资源层、硬件层等监控，每层监控指标各不一样。只有做到完整立体监控，才能及时发现潜在问题。

不同层次的监控指标：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/euN1ic17Jn05thgibB407G8kY8S0HYT5c6EwN9UH7ibjzmPu1k66DIRhlluRWT1JQjlpO948KVbQOjkjZeLI5iagvA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

## 5 大促预案

突发情况可能在系统任何一个环节出现。因此，在梳理预案的时候，我们会根据系统的关键链路寻找链路上的关键节点，并针对关键节点制定预案。

常见突发情况：活动配置错误、接入层不稳定、服务自身bug、依赖存储层服务不稳定、依赖下游服务不稳定、依赖中间件不稳定等。

根据阶段不同，预案分为前置预案、应急预案和恢复预案。

![图片](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jhKlnucuGDh4qgKzZeBfW2Gdy2AiaB8X3mMSzSfNNPibuVIXXNZkhywdg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 6 故障演练

这些预案在故障发生时是否真有效？处理问题人是否熟练？沟通机制是否顺畅？所以应在线上环境隔离真实流量的情况下，提前模拟各种可能故障，来观察系统的反应和人员处理情况，以验证预期策略。

于是，在大促前我们都会进行故障演练，以低成本的方式发现预案的不足，暴露系统的问题，不断提高人员及系统的能力。

### 6.1 人员分工

故障演练不仅包含突发情况应对预案，也包含不同职能人员分工。聚集职能内责任，保证信息的有效流转，提高发现问题、执行预案的效率。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jt0NvYyJyeURec3SdCIRRgv1WHA3BtZhuMj2TCGV5wpl1sclWviaiaM6A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

除了破坏组是为故障演练而设，其他都是在真实大促活动中切实存在的。在每次大促时，相关职能的人员都会值班待命，随时处理大促过程中出现的异常情况。

### 6.2 演练过程

#### 6.2.1 故障演练前

- 检查必备基础能力：流量注入及流量染色等能力，保证流量不影响真实用户
- 确定故障演练范围、环境：跟当地运营人员确定可演练的真实线上环境，确保没有真实流程，或实施流量隔离，不影响真实用户；
- 确定故障及应对预案：确定要演练的故障，制定好故障剧本，并针对故障制定相应预案；
- 通知涉及的外部人员：将可能的影响面提前通知相应外部人员。

### 6.2.2 故障演练中

![图片](https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05S0uUO56mJ7rUn5YeliaB2jacZjFLaBT3v77lgIibxNfdfcA0Pr3Gx7yWJuBeQYsTS6KPj4iaUicbwsw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

被染色的流量注入系统的那一刻起，故障演练就正式拉开序幕。据上图所示，整个演练流程分为八个主要步骤：

1. 破坏组按故障剧本，注入故障到演练系统；
2. 定位组观察各指标，及时发现故障，进行初步定位，排查问题；
3. 定位组汇总关键信息上报故障给决策组；
4. 决策组收到故障报告，根据关键信息决定是否执行预案，并告知执行组决策结果，要求执行某个预案；
5. 执行组收到决策组的决策结果，执行某个预案；
6. 执行组将执行结果反馈给决策组；
7. 决策组同步预案执行结果给定位组；
8. 定位组观察预案执行后的指标是否恢复，并将结果反馈给决策组及其他人员。

### 6.2.3 故障演练后

- 现场清理：如流量关闭、撤销故障、关闭预案、清理演练的数据等；
- 通知相关人员演练结束；
- 演练报告与总结：包括是否达到预期目标、预案有无生效、是否有预料之外的状况发生，并对关键指标（业务指标、机器负载指标）收集归纳，整理后续改进点。

## 7 总结

大流量冲击下，系统保持稳定需要靠系统性思维，不仅要考虑系统自身情况，更重要的是技术团队要不断总结教训，积累实践经验，提高自身能力。

面对大促，团队要做到：

- 充分了解业务特点，设计出符合业务特点的技术构架，并且全面考虑高并发场景，综合运用高并发技术
- 要充分了解大促流量分布情况、流量预估，做出合理容量规划
- 要通过各种外部系统，如监控、日志等了解系统的运行情况，及时发现问题、解决问题，提高可用性
- 要有应急预案思维，提前做好各关键节点的预案，多做故障演练，提高应对各种突发情况的处理能力

现有系统及预案还有值得完善的，后续优化方向：

- 系统接入层增加限流机制，防止系统过载而崩溃
- 增加更多的预案，扩大预案覆盖面。有些预案由于系统架构或外部原因导致无法执行，后续也会持续改进
- 增加故障演练次数及演练的场景，提高团队应对能力

参考：

- https://mp.weixin.qq.com/s/A524PBZW2ARFNunDwD6FkQ
- https://mp.weixin.qq.com/s?__biz=MzkzMDE5MDgwMQ==&mid=2247488707&idx=1&sn=ff14cf5fd541d33a012bbd9ef1a4ff54&chksm=c27f507df508d96b381bbec6314378e2f67d6d184f8cd0d748f9ae92a3a30b1a323a578aaee2&scene=178&cur_album_id=2037133284337336322#rd
- https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkzMDE5MDgwMQ==&action=getalbum&album_id=2009422776318640131&scene=173&from_msgid=2247488707&from_itemidx=1&count=3&nolastread=1#wechat_redirect