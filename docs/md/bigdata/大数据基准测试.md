# 大数据基准测试

## 0 前言

大数据不但有各种直接进行大数据处理的平台和框架，如HDFS、MapReduce、Spark，还有周边支撑工具，如大数据基准测试工具。

## 1 主要用途

对各种大数据产品进行测试，检验大数据产品在不同硬件平台、不同数据量、不同计算任务下的性能表现。

12年Hive只能做离线SQL查询计算，无法满足实时交互查询需求，业界需更快的ad hoc query（即席查询，一种非预设查询的SQL访问）工具。Cloudera推出准实时SQL查询工具Impala。Impala兼容Hive的Hive QL语法和Hive MetaSotre，也支持Hive存储在HDFS的数据表，但放弃Hive较慢的MapReduce执行引擎，而基于MPP（Massively Parallel Processing，大规模并行处理）架构重新开发执行引擎，获得更快查询速度。

用四台服务器部署小集群，利用大数据基准测试工具HiBench对Impala和Hive做对比测试：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/11/d53ffd8eaf244ac760bf7eb8382eab83.png)

并不乐观。Impala性能优势在聚合查询，即group by查询的SQL语句；而对连接查询，即join查询的SQL性能很差。适合Impala的应用场景：

- 简单统计查询，对单表数据进行聚合查询，查看数据分布规律
- 预查询，在进行全量数据的SQL查询之前，对抽样数据进行快速交互查询，验证数据分析师对数据的判断，方便数据分析师后续设计全量数据的查询SQL，而全量数据的SQL还是要运行在Hive

Impala尴尬了，定位似乎Hive附属品，但Cloudera寄予厚望，Cloudera投入公司近一半工程师到Impala开发，Impala不断迭代，性能很大改进。

12年，Intel大数据团队用大数据基准测试工具HiBench对Spark和MapReduce对比测试后发现，Spark运行性能有惊人表现。Intel成Spark最早参与者，加速Spark发展。13年Spark加入Apache开源计划，迅速成为Apache顶级项目。所有各方都是赢家，Spark、Intel、Apache乃至整个大数据行业。好工作不光对公司有利，对员工也有利。工作不是公司压榨员工过程，而是公司创造价值，员工也实现自我价值过程。

咋才能创造好的工作也不只是公司责任，主要还靠员工，去发现哪些事能让自己、公司、社会获益，去推动落实，虽然有时推动比发现更难。同时拥有发现和推动能力的人，毫无例外都是出类拔萃之人。

## 2 HiBench

Intel推出大数据基准测试工具HiBench，内置若干主要的大数据计算程序作为基准测试的负载（workload）：

- Sort，对数据进行排序大数据程序。
- WordCount，前面多次提到过，词频统计大数据计算程序。
- TeraSort，对1TB数据进行排序，最早是一项关于软件和硬件的计算力的竞赛，所以很多大数据平台和硬件厂商进行产品宣传的时候会用TeraSort成绩作为卖点。
- Bayes分类，机器学习分类算法，用于数据分类和预测。
- k-means聚类，对数据集合规律进行挖掘的算法。
- 逻辑回归，数据进行预测和回归的算法。
- SQL，包括全表扫描、聚合操作（group by）、连接操作（join）几种典型查询SQL。
- PageRank，Web排序算法。

还有十几种常用大数据计算程序，支持MapReduce、Spark、Storm等。

HiBench价值不在对各种大数据系统基准测试，而是学习大数据、验证自己大数据平台性能。PC部署伪分布式大数据集群容易，但接下来？开发MapReduce程序、打包、部署、运行，可能每步都会遇到挫折。即使一切顺利，但大量数据才有意义，数据从哪来？如想用一些更复杂应用体验大数据威力，挫折更多，所以很多人安装Hadoop后，就放弃大数据。

大数据平台工程师若等使用者抱怨自己维护的大数据平台不稳定、性能差，就晚了，因为这些消息可能已传到老板耳。所以必须自己不停跑测试，了解大数据平台状况。有HiBench，这些问题就可解决，其内置主要大数据程序，支持多种大数据产品。使用简单，可将HiBench作学习工具，很快运行各种数分和机器学习大数据应用。大数据工程师也可用HiBench测试自己的大数据平台，验证各种大数据产品性能。

## 3 使用

1.配置，配置要测试的数据量、大数据运行环境和路径信息等基本参数。

2.初始化数据，生成准备要计算的数据，比如要测试1TB数据的排序，那么就生成1TB数据。

3.执行测试，运行对应的大数据计算程序。

初始化和执行命令简单，如要生成数据，只需运行bin目录对应workload的prepare.sh自动生成配置大小的数据：

```bash
bin/workloads/micro/terasort/prepare/prepare.sh
```

执行大数据计算，运行run.sh：

```bash
bin/workloads/micro/terasort/hadoop/run.sh
bin/workloads/micro/terasort/spark/run.sh
```

## 4 总结

同一类技术问题的解决方案不会只有一个，技术产品也不会只有一个，如大数据领域，Hadoop到Spark到Flink，各种大数据产品层出不穷，咋对比测试这些大数据产品，在不同应用场景中它们各自的优势是啥？就要用到基准测试工具，用最小成本得到想测试的结果。

所以很多技术领域都有基准测试，如数据库、os、计算机硬件等。前几年手机领域竞争聚焦配置和性能，“跑个分试试”，这也是一种基准测试。得到业界普遍认可的基准测试工具就是衡量这些产品优劣的标准，如能使基准测试对自己产品有利，更涉及巨大商业利益。

有时想了解大数据产品性能和用法，看资料花很多时间，最后得到的可能还是一堆不靠谱N手信息。但自己跑基准测试，也许就几分钟，再花点时间看看测试用例，从程序代码到运行脚本，很快就能了解其基本用法，省时、高效。