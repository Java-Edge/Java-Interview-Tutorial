# 队列积压了百万条消息，线上直接OOM了！

## 0 前言

某系统不停发布数据到Kafka，数据同步系统专门从Kafka消费数据，再保存到自己数据库，可类比物联网数据网关系统：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/07/efda53ea36744e44442fd1cc0aca94d0.png)

这么简单的系统，居然时不时报OOM，得重启，过段时间又OOM。而且这系统处理数据量越来越大，OOM频率也越来越高。

## 1 从现象看本质

既然每次重启后，都会在一段时间后OOM，说明肯定是每次重启后，内存都不断上涨。一般要高到OOM，通常就是因为：

- 并发太高，瞬间大量并发创建过多的对象，导致系统宕机
- 内存泄漏之类，即很多对象都赖在内存不死，无论怎么GC都回收不了

而该系统负载并不高，虽数据量不少，但绝非瞬时高并发。

看来可能就是随时间推移，某种对象越来越多，赖在内存。然后不断触发GC，结果每次GC都回收不掉这些对象。一直到最后，内存实在不足，造成 OOM：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/07/158f4100c828f9ca99b32462d96d094c.png)

## 2 jstat验证

直接在一次重启系统后，jstat观察JVM运行情况：

发现，Old对象一直不停增长。每次YGC后，老年代对象就增长不少。且当老年代使用率达100%后，正常触发Full GC，但Full GC回收不掉任何对象，导致老年代使用率还是100%！

然后老年代使用率维持100%一段时间后，就OOM了，因为再有新对象进入老年代，实在没空间放了！

这就验证了判断，每次系统启动，有啥对象，会一直进堆内存，且随YGC执行，对象会一直进入老年代，最后触发Full GC都无法回收老年代的对象，导致OOM。

## 3 MAT/JProfile找到占用内存最大对象！

内存快照中发现有个队列数据结构，直接引用大量数据，就是这队列数据结构占满内存！ 

### 3.1 这队列做啥的？

从Kafka消费出的数据会先入队，再从队列慢慢写入DB，主要是要额外做中间数据处理和转换，所以自己在中间又加个队列：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/07/cf0ae92959bf99ff261cc4f6bb3e5c62.png)

### 3.2 这队列咋用的？咋随便用就出问题！

从Kafka批量消费，可能一次消费几百条数据。因此，coder直接每次消费几百条数据出来给做成一个List，然后把这List入队！ 

最后就搞成：若一个队列有1000个元素，每个元素都是个List，每个List里都有几百条数据！

这就导致内存队列积压几十万甚至百万条数据！最终一定OOM！ 而且只要你数据还停留在队列中，就无法被回收！

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/07/2f415b27f7b58fbb461d057eb576ddc9.png)

这是典型的对生产和消费的速率没控制好：

- 从Kafka消费出来的数据，入队速度很快（生产者速率很快）
- 但从队列里消费数据进行处理，然后写DB速度较慢（消费者速度很慢）

最终导致内存队列快速积压数据，导致OOM。而且这种队列每个元素都是个List或者大对象，就会导致内存队列能容纳的数据量极速增长，提前OOM。

## 4 解决方案

修改内存队列的使用，做成定长的阻塞队列。

如最多1024个元素，每次从Kafka消费出来数据，一条条写入队列，而不是做成一个List入队作为一个元素。

这样内存中最多1024个数据，一旦内存队列满，此时Kafka消费线程就会停止工作，因为被队列给阻塞住了。不会让内存队列中的数据过多：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/07/49e8882bf632f5e70d85de1386a6aef0.png)