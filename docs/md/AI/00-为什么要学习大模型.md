# 00-为什么要学习大模型

## 0 prompt engineer

就是prompt工程师它的底层透视。

## 1 学习大模型的重要性

### 底层逻辑

人工智能大潮已来，不加入就可能被淘汰。就好像现在职场里谁不会用PPT和excel一样，基本上你见不到。你问任何一个人问他会不会用PPT，他都会说会用，只是说好还是不好。你除非说这个岗位跟电脑完全无关。但凡说能用上电脑的，基本上都会用excel和PPT，你不会用的基本上都被淘汰了，逻辑一样。

人工智能虽有一些应用场景，好像跟普通人没关。如智能驾驶，人脸识别，好像跟普通人关系不太大，我们都是被动使用。但现在这大模型跟我们每个人都有关，它是一个强大提升工作效率工具。你不会用，将来就好像跟PPT和excel一样，你就会慢慢的被职场淘汰。

会用就行？好像我们会用大模型，好像很简单对吧？无论是文心，还是通义千问，还是ChatGPT，用起来很简单，就是聊天不就OK？但其实不够，因为我们用它不只是当搜索引擎，用它是为提升工作效率，所以还要用的好。

### 啥叫用的好？

如写文章，PPT，写excel，可让他给你进行优化。甚至codding，也可让大模型帮你写。当然说让它完全替代你的代码不可能，但是你可以用它给你写一些框架性东西或具体的一个小问题，可直接让他写，然后拿过来你试下好不好用，甚至有bug也可以让他改一下。这样其实还是大幅度提升工作效率，最终跟PPT和excel依然逻辑类似。

## 2 大模型的潜力与微调

大模型是人工智能代表，潜力与使用方式有关。使用好大模型可提高效率，让人获得更好的待遇和更多机会。然而大模型潜力要通过微调挖掘，以适应不同场景和需求。大模型出现引发行业需求爆发，尤其随ChatGPT到来，其问答能力超过临界值，行业需求将逐渐增加。

你发现PPT和excel用的好的PPT一看就惊艳，excel用的特别熟练，你这个数据分析用的非常的到位，你的待遇会远远高于那些用的不好的。大模型也一样：

- 用好你可几倍于原来效率
- 用不好，你可能跟原来没什么区别

差距非常明显，有人就可一人干两人活，那待遇肯定远高于能保持原效率的人。大模型底层逻辑用的不好：

- 要么没挖掘出大模型潜力，你只是让他答一些普通问题
- 要么就是你这个prompt写的不好，他就开始胡乱回答
- 或你问的问题范围不好，他就开始胡乱回答

这都是用的不好的一些标志，但最终你用的好。

假设你已通过各种尝试磨练或技巧学习，把某模型潜力发挥到极致。如文心一言最终能解决所有问题吗？也不行，就比如大模型不会回答关于你公司内部信息问题，因为他不知道，他没训练过。

当然现在通过知识库可部分解决这个问题，但知识库不是万能，最终他一定会有场景需要训练。比如说你想调整他回答的语气，让他活泼点或更官方点或让他的回答的更有一些个人特色。这种场景的大模型，因为它没有训练这种内容，所以它不可能满足你的需求。你一定要对它进行训练，至少微调。

所以总结下，大模型是一个非常强大的一个工具，他作为人工智能代表，AIGC已来到普通人接受范围内。这时不仅要会用，还要用好，甚至会微调，才能拉开跟其他职场人员的差距。这样我们的待遇才能更丰厚，工作机会更多。

你要学习到第二点，就是行业需求爆发了，就是基点以来。自从大模型出现，它的问答能力突破了一个临界值，就好像都有一个值。以前的模型都在临界值下徘徊，导致很难商用，只能在学术界兜转。直到ChatGPT才迈过这阀值，就是我们能接受的门槛，错误已经少到一定界限。这种我们会发现他已经可以用了，问什么问题都能回答上来，这就是基点。这就导致行业需求其实是慢慢会爆发起来的，它应对哪些场景呢？

## 3 大模型的应用需求

大模型在公司内部问题解决、产品解答、智能聊天和游戏NPC等方面的应用需求。大模型的使用可以提高效率、流畅度和人机交互体验。随着需求的增加，相关工程师的需求也会提升。

### 对内

像OAERPCRM等这些问题。平时都是是文档来文档去，比如说里面OA公司的制度都是文档，某人对某制度疑惑，要么问HR或行政，整体效率低。未来这些知识其实全部都可接到一个大模型之后，让一个模型加一个知识库，效率大大提高。

### 对外

也有类似客服解答产品的这种需求。每个公司都有自己的一些产品，有些产品边界、产品参数，还有一些应对各种情况的服务之类的，都要解答客户问题。现在解决方法一般先建一个官方网站里面介绍产品，然后后面再对接一个真人客服，当然也会加一些智能客服内容，但总体效果不如未来使用大模型加知识库，然后还有智能聊天，这是最底层需求。但现在人越来越忙，尤其老年人，他们没人聊天。这需求其实非常大，但一直没有被满足。但总之现在大模型出现之后，让问题看见曙光。

### 智能NPC

如游戏里面的NPC都是写死的，都是给你一个逻辑控制，遇到啥场景他做啥回答，完全写死，所以感觉刻板。如将来游戏NPC也接入大模型，让他对话更流畅，更像一个人。但这个游戏里面单纯的找各种不同人对话，是不是感觉也很有意思？这就是游戏里需求，也非常大。尤其未来元宇宙如果出现vr、ar都结合上之后，再加大模型，这里面的需求场景几乎无限大。

行业需求爆发，是不是可能让从事相关工作的工程师的待遇进行提升？肯定的，不过个案不能代替全部。如果说按一个行业，它总体待遇是由供需关系和创造价值量决定的。但是总体上它的需求产生了爆炸性提升。但总体上，互联网其实就是一个这样一层一层往上叠代爆发的过程。

## 4 互联网行业技术发展与工资待遇

互联网行业工资待遇高的原因是因为需求突然爆发，供应不足；互联网是编辑成本低的行业；创造的价值量与用户量成正比，但成本不成正比；技术的发展也是一层一层往上叠代的，学习最顶层的技术才能拿到高薪。

互联网刚出，你会个HTML，简单JS，工资可能就拿非常高。当时根本无法想象的。90年代当时美国互联网泡沫，你就是会一个HTML这么简单的一个东西就可以拿很高的年薪。就是因为这个需求突然爆发了，但供应提不上来，没那么多人会，所以工资待遇高。而且互联网又是一个编辑成本很低的一个行业。就是你只要做出一个东西，可以给全球每一个人看你这个成本，还是原来的成本不会增加太多。

这就是为什么互联网行业的待遇容易比较高，这就是创造的价值量跟你的用户量成正比，但是你的用户量跟你的成本却不成正比。你一个用户成本跟100万个用户的成本其实差不了许多，差的可能你就是服务器成本，但是你主要的研发成本差不多，剩下主要是供需关系。

最开始HML假设在这位置，然后就是ASP、PHP语言刚出来的一些动态页面，会这些语言你就高薪。再往后安卓出来智能手机IOS之前可能还有java，java是在这位置后，然后IOS和安卓它是一层一层往上开发，然后到算法，现在到了大模型。

你现在再学习下面的东西，如HTML，PHP5、java。在现在这个位置学习他，你不可能高薪，因为它已是基础设施。就好像你开发应用一样，你现在去开发操作系统，你除非说国产替代，正常来讲，微软和苹果已把操作系统完全占领，你不可能再打开空间。再往上，可能微信QQ之类的，你再开发一个类似的，也不可能打败它。

跟这个技术的原理是类似的，技术也是一层一层往上叠代。你现在这个角度去学习更底层东西。不是说完全没必要学，如果说你有时间可学习，这样知识体系更完整。但仅靠下面知识找工作，高薪不易。你只有拿最顶层技术，可能高薪。

## 5 大模型训练经验与高薪offer

前段时间有个大模型训练的拿到200万年薪。工作经验只有六年。他为什么那么高offer？大模型经验他比较多，大模型其实是GPT3出来后，CP3出来到现在大概也就三年。算上GBTR大概四年，他在阿里就有四年大模型训练经验，很难得。

模型本身其实现在工作需求已比较大。如果说它下面游戏NPC有了一个突破，然后你又比较熟悉这方向，会的人又比较少。这时你立马就可跳槽拿高薪。

## 6 为啥通过本套专栏学习大模型？

这套专栏是围绕大模型，就围绕ChatGPT进行组织的。首先基于ChatGPT的历史发展开始讲解前后左右：

- 前就是它的历史
- 后讲大模型延伸。高效微调训练也会讲，但是我们完整的这个175B的ChatGPT训练不动。所以用了高效微调训练了一个6B的模型及launch基于long ten结合一个稍微小一点的语言模型6B的进行一些应用的开发，这是后面
- 左右就是用到了强化学习，在ChatGPT训练的时候用到了强化学习。展开讲了，避免你产生一些知识盲区。

不像有的说讲这个ChatGPT，直接把NLP1大套底层的知识都搬给你，这些也不是没有用。但是就对你这个主题稍微有点偏会，导致你如果说这个东西肯的时间太长，会让你兴趣丧失，不太利于你学习。这个知识用到的知识我都给你讲了也不会显得过于单薄。

现在关于大模型或ChatGPT专栏，主要还是一些帖子或简单专栏。它对它的GPT依赖的一些知识，如transformer、历史，还有强化学习都不太多。这就需要你有比较多的基础知识才能看那些课。我这课相对降低你对基础知识要求。讲课的时候也包含了一些底层的思考，你也可以认为是一些类比，能让你更好的理解这些模型到底是在干什么。

## 7 专栏学习方法及收获

现在训练专栏都不系统，因为ChatGPT是新兴事物，22年8月才出现，然后11月才火起来，至今不满2年。要么它就是基于传统的NOP专栏，然后再单独开一张，介绍一下全程PPT。

### 学习方法

不只是学习本套专栏的方法，其实学习所有人工智能你都可以用这套方法，就是关于数学公式推导。人工智能有大量数学公式推导，是人工智能专栏最大难点，但你数学不好，又想学课咋办？建议先跳过，先扫两眼公式，感觉看懂就看看。看不懂跳过，把公式推倒当成黑盒，只记结论及逻辑。但建议你有能力，感觉数学还可，还是把公式啃完，当然了大部分应用开发工程师不需要。

### 收获

你会学习到ChatGPT等大模型训练原理，即：

- 底层原理
- 如何训练

然后掌握多种NLP逻辑，因为fort它是为了解决下游NLP任务的，如文本分类，N12，阅读理解。所以本套专栏其实都会在介绍port时候介绍一些逻辑。用它们解决下游任务也比较简单，在代码实践上也进行了一个样例的操作，可上手解决实际问题。你就拿一个人家训练好的波尔模型拿过来，然后在下游进行或者分类，或者说NE2，去接一下不同的下游处理，就可以直接上手处理不同的任务，或者一般还是需要微调的，所以你再训练一下就可以解决实际问题了。

然后理解bert和GPT的模型异同，实际上是bert系列和GPT系列他们的模型的差异。然后学会高效调参技巧，如peft和 Langchain。简单理解就是你的显存不够时，还能把这个大模型训起来。如6B13B都可训起来。最后就学会用浪琴加上不同大模型。如千问模型再加一个知识库向量数据库，如face搭建一个自己的智能助手，这是收获。

## 8 适合人群

想从零开始学习chat GP的人群。基础不多想学没关系，数学基础不是那么的优秀也可学。可把数学公式推导先跳过。后面对数学有兴趣，把这基础补补再来看也OK

想理解大模型底层原理，以便更好使用大模型。如为什么大模型避免不了幻觉，就是说它避免不了胡乱回答。你只有理解底层原理才知为什么，你才能尽量的有指导性去回避让他乱答。

想自行训练和搭建大模型服务的人群。要么就是外包，你给别公司去搭建。要么就是你在公司里其他人都不会，又不想花很多钱去买外包服务。但自己学一下给自己公司搭一个大模型的服务地图储备，这个其实还看目的。如只是想学会它底层原理，然后去更好使用这些模型，那懂点点python、linux就可。对技术依赖不多。但如果说你想训练场，你想玩的更彻底，那我的建议还是要有一些数学基础，有一些人工智能基础。

## 9 提供服务

问题的解答。这个问题我这边是定期会看问题，然后定期回答。

在线笔记，还会拉一个群，这样与其他的小伙伴们一起交流。

有些问题，其他同学还要好，互相之间交流有时也很重要，这就是导学。