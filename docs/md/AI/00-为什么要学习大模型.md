# 为什么要学习大模型

## 1 学习大模型的意义

### 1.1 底层逻辑

AI大潮已来，不加入就被淘汰。就像现在职场谁不会用PPT和excel一样。你问任何一个人他会不会用PPT，都说会用，只是说好还是不好，除非岗位跟电脑完全无关。但凡用电脑，基本都用excel和PPT，不会用的基本都被淘汰，逻辑一样。

#### AI虽有应用场景，好像跟普通人无关？

如智能驾驶，人脸识别，跟普通人关系不大，我们都是被动使用。但现在大模型跟我们每人都有关，强大的提升工作效率工具。你不会用，就好像跟PPT和excel一样，你就会慢慢被职场淘汰。

#### 会用就行？

用大模型，好像很简单。无论通义千问、ChatGPT，用起来简单，聊天就OK。但还不够，因为我们用它不只是当搜索引擎，用它是为提升工作效率，得用的好。

### 1.2 啥叫用的好？

如写文章、PPT和excel，让他给你优化。甚至coding，让大模型帮你写。完全替代你的代码不可能，但给你写一些框架性东西或具体一个小问题，然后拿过来你试下好不好用，有bug也可让他改。还是大幅提升工作效率，最终跟PPT和excel依然逻辑类似。

## 2 LLM潜力与微调

LLM是AI代表，潜力与使用方式有关。潜力要通过微调挖掘，以适应不同场景和需求。大模型出现引发行业需求爆发，尤其随ChatGPT问答能力超过临界值，行业需求逐渐增加。

PPT和excel技能高的的PPT一看就惊艳，excel用的特熟练，你这数据分析用的非常到位，待遇自然远高于那些用的不好的。LLM同理：

- 用好，几倍原效率
- 用不好，就感觉和现状无区别

差距明显，有人可一人干两人活，待遇肯定高于原效率的人。

### LLM底层逻辑用的不好

- 没挖掘出大模型潜力，你只是让他答普通问题
- prompt写不好，他就乱答
- 问的问题范围不好，也不着边际乱答

这都是用的不好的标志。

若已通过各种尝试磨练或技巧学习，把某模型潜力发挥到极致。如ChatGPT最终能解决所有问题吗？也不行，就比如大模型不会回答你公司内部信息问题，因为他不知道，没数据训练过。

通过知识库可部分解决这问题，但知识库不是万能，最终会有场景需要训练。如想调整他回答的语气活泼点或更官方点或有些个人特色。这种场景大模型，因为没有训练这种内容，所以不可能满足你的需求。你要对它训练，至少微调。

所以不仅要会用，还要用好，甚至微调，才能拉开跟其他职场人差距。待遇才能更丰厚，工作机会更多。

### 问答能力突破临界值

行业需求爆发，自大模型出现，问答能力突破临界值。以前模型都在临界值下徘徊，难商用，只能在学术界兜转。直到ChatGPT迈过阀值，错误少到一定界限。问什么都能回答，这就是奇点。导致行业需求爆发。

## 3 大模型的应用需求

公司内部问题解决、产品解答、智能聊天和游戏NPC等方面的应用需求。大模型可提高效率、流畅度和人机交互体验。随需求增加，相关工程师需求也会提升。

### 3.1 对内

像OA、ERP和CRM等问题，平时都是文档来文档去，如OA公司制度都是文档，某人对某制度疑惑，要么问HR或行政，整体效率低。这些知识全都可接入大模型，模型+知识库。

### 3.2 对外

类似客服解答产品的这种需求。每个公司都有自己的一些产品，有些产品边界、产品参数，还有售后服务之类，都要解答客户问题。

现解决方案是一般先建一个官方网站介绍产品，后台再对接一个真人客服，当然也会加一些智能客服内容，但总体效果不如用大模型+知识库的智能聊天。

现在人越来越忙，尤其老年人，他们没人聊天。这需求其实非常大，但一直没有被满足。

### 3.3 智能NPC

如游戏里NPC都是写死，都是给你一个逻辑控制，遇到啥场景他做啥回答，感觉刻板。如将来游戏NPC接入大模型，对话更流畅，更像人。但这个游戏里面单纯的找各种不同人对话，是不是感觉也很有意思？vr、ar都结合后，再加大模型，需求场景几乎无限。

## 4 互联网行业技术发展与工资待遇

行业需求爆发，是不是能让从事相关工作的工程师的待遇提升？肯定的，不过个案不能代替全部。

一个行业，总体待遇由供需关系和创造价值量决定。互联网行业待遇高的原因是需求爆发，供应不足；互联网是编辑成本低的行业；创造的价值量与用户量成正比，但成本不成正比；技术发展也是一层层迭代，学习最顶层技术才能高薪。

互联网初期，会HTML，简单JS，工资就很高。就是因为需求爆发，但供应提不上来，没那么多人会，所以工资待遇高。

互联网又是一个编辑成本低的行业。只要做出一个东西，可给全球每个人看，还是原来成本，不会增加太多。

这就是为啥互联网行业待遇较高，这就是创造的价值量跟用户量成正比，但用户量跟你的成本不成正比。1个用户成本跟100万个用户成本差不了许多，可能就服务器成本，但主要研发成本差不多，剩下主要是供需关系。

最开始HTML假设在这位置，再就是ASP、PHP刚出来的一些动态页面，会这些就高薪。再安卓，出来了智能手机和Java。IOS和安卓一层层往上开发，到算法，现在到大模型。

再学习如HTML，PHP、Java，你不可能高薪，因为它已是基础设施。就好像你开发应用，你现在去开发操作系统，除非国产替代，正常来讲，微软和苹果已把os完全占领，不可能再打开空间。再往上，可能微信QQ之类，你再开发类似，也不可能打败。

技术层层往上迭代，你现在角度去学习更底层东西。不是完全没必要学，若你有时间可学，这样知识体系更完整。但仅靠下面知识找工作，高薪不易。你只有拿最顶层技术，更可能高薪。

## 5 大模型训练经验与高薪offer

前段时间有大模型训练200万年薪。工作经验只有六年。因为他大模型经验多，大模型其实是GPT3出来后，到现在也就三年，算上GBTR大概四年，他在阿里就有四年大模型训练经验，很难得。

模型本身工作需求已较大。若它下面游戏NPC有突破，然后你又比较熟悉，会的人又少。立马可跳槽高薪。

## 6 为啥通过本专栏学习大模型？

专栏围绕大模型，就围绕ChatGPT、通义千问组织。先基于ChatGPT的历史发展开始讲解前后左右：

- 前，就是它的历史
- 后，讲大模型延伸。但完整175B ChatGPT训练不动。所以用高效微调训练一个6B模型及langchain结合小模型6B进行应用开发
- 强化学习，在ChatGPT训练时用到

不像有的人讲ChatGPT，直接NLP一大套底层知识搬给你。这些不是没用，但对你入门主题偏离，导致理论啃太久，兴趣丧失，不利学习。等用到这些知识再回看就不显得单薄。

现关于大模型或ChatGPT专栏，主要还是一些帖子或简单专栏。对GPT依赖知识，如transformer、历史，强化学习都不多。需有较多理论基础知识才看懂。而本专栏相对降低对基础知识要求。讲解时也包含一些底层思考和类比，让你更好理解这些模型到底在干啥。

## 7 专栏学习方法及收获

现在训练专栏都不系统，因为ChatGPT是新兴事物，22年8月才出现，然后11月才火起来，要么它就是基于传统的NLP专栏，然后再单独开一张，介绍全程PPT。

### 7.1 学习方法

不只是学习本套专栏的方法，其实学习所有人工智能你都可以用这套方法，就是关于数学公式推导。人工智能有大量数学公式推导，是人工智能专栏最大难点，但你数学不好，又想学课咋办？建议先跳过，先扫两眼公式，感觉看懂就看看。看不懂跳过，把公式推倒当成黑盒，只记结论及逻辑。但建议你有能力，数学还可，就把公式啃完，当然大部分应用开发工程师不需要。

### 7.2 收获

你会学习到ChatGPT、千问等大模型训练原理，即：

- 底层原理
- 如何训练

再掌握多种NLP逻辑，因为fort就是为解决下游NLP任务，如文本分类，N12，阅读理解。就拿一个人家训练好的Bert模型拿过来，然后在下游进行或者分类，或者说NE2，去接一下不同的下游处理，就可以直接上手处理不同的任务。一般还是需要微调，所以你再训练即可解决实际问题。

理解bert系列、GPT系列模型差异。学会高效调参技巧，如PEFT和 Langchain。就是显存不够时，还能把LLM训起来，如6B、13B。最后用langchain加不同LLM如qwen+知识库使用向量数据库，搭建一个自己的智能助手。

## 8 适合人群

想从0开始学习ChatGPT的人群。基础不多想学没关系，数学基础不是那么的优秀也可学。可把数学公式推导先跳过。后面对数学有兴趣，把这基础补补再来看也可。

想理解大模型底层原理，以便更好使用大模型。如为啥大模型避免不了幻觉，就是说它避免不了回答。只有理解底层原理才知为什么，你才能尽量有指导性去避免他乱答。

想自行训练和搭建大模型服务的人群：

- 外包，你给别公司去搭建
- 你在公司里，其他人都不会，又不想花很多钱去买外包服务

但自己学一下给自己公司搭一个大模型服务做储备，也看目的：

- 只想学底层原理，去更好使用这些模型，那懂点python、linux就可，对技术依赖不多
- 但想训练它，想玩更彻底，还要有数学和AI基础