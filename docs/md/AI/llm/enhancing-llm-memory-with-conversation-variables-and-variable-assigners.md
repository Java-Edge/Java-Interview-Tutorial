# Dify v0.7.0利用对话变量与变量赋值节点增强 LLM 记忆能力

## 0 前言

Dify一直致力于优化大语言模型（LLM）在应用中的记忆管理，以更好地应对各种具体场景需求。虽 LLM 能通过上下文窗口存储对话历史，但因为注意力机制的限制，在复杂场景中往往会出现记忆断层或聚焦不精准的问题。

Dify 最新版本为此引入了两个新功能：

- **对话变量（Conversation Variables）** 
- **变量赋值节点（Variable Assigner nodes）**

结合使用，可让基于 Chatflow 构建的 LLM 应用拥有更加灵活的记忆控制能力，支持读取与写入关键用户输入，从而提升 LLM 在生产环境中的实用性。

## 1 对话变量：精准存储上下文信息

允许 LLM 应用存储并引用上下文信息。开发者可在 Chatflow 会话中临时保存特定数据，如上下文内容、用户偏好，未来还将支持上传文件等内容。通过 **变量赋值节点**，可以在对话流程中的任意位置写入或更新这些变量。

![](https://framerusercontent.com/images/1g1h1dXMj3bbNDJuZsNJuiMQM.png)

### 优势

- **精准的上下文管理：** 以变量为单位管理信息，而不仅仅是整个对话历史
- **支持结构化数据：** 能处理字符串、数字、对象、数组等复杂数据类型
- **便于流程集成：** 可在 Chatflow 的任何节点中写入或更新变量，供后续的 LLM 节点使用

相比默认的对话历史机制，对话变量提供了更精细的信息管理方式。它让应用能够准确记住并调用特定信息，实现更加个性化的多轮对话体验。

## 2 变量赋值节点：设置并写入对话变量

要用于为可写变量（如对话变量）设置值。这类节点允许开发者将用户输入暂存，以供后续对话中引用。

![](https://framerusercontent.com/images/pK0I2CwviMO3FH5hBBOHbXKE8y8.png)

如在需要记录用户初始偏好的应用中，可结合使用对话变量和变量赋值节点来：

- 存储用户的语言偏好
- 在后续回复中持续使用该语言

举例来说，若用户在对话开始时选择中文，变量赋值节点会将该偏好写入 `language` 对话变量。随后，LLM 就会依据该变量，在整个对话过程中持续使用中文。

![](https://framerusercontent.com/images/iMhO0gdxvGAVyhT4ho0sYtid9M.png)

这种做法简化了偏好的捕捉与应用流程，提升了对话的连贯性与用户体验。

## 3 更多应用场景

远不止于偏好存储，还可用于：

- **患者接待助手：** 将用户输入的性别、年龄、症状等存入变量，用于推荐合适的就诊科室

- **对话摘要生成器：** 通过变量赋值节点提取摘要，避免加载完整对话历史造成记忆超载

- **数据分析助手：** 在对话中调取外部系统数据，并用于后续交互中

- **创意写作工具：** 以对象数组形式动态存储和修改故事元素：

  ```json
  [
    { "name": "Alice", "role": "主角", "trait": "勇敢" },
    { "name": "神秘森林", "type": "场景", "atmosphere": "诡异" }
  ]
  ```

这些示例展示了对话变量与变量赋值节点如何满足复杂应用对个性化记忆的需求，进一步提升 LLM 应用在实际场景中的能力与表现。