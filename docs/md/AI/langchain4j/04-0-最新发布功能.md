# 0.1.0 ~ 0.24.0

## 0.24.0

Nov 13, 2023

- [@riferrei](https://github.com/riferrei) 贡献的 [OpenSearch](https://opensearch.org/) 集成
- Vertex AI：以 5 个一批的方式嵌入
- [@Heezer](https://github.com/Heezer) 贡献的 Milvus 数据库名称配置支持
- OpenAI：添加了设置自定义 Tokenizer 的选项，将默认超时时间增加到 60 秒
- Azure OpenAI：将默认超时时间增加到 60 秒
- [@marlukcz](https://github.com/marlukcz) 贡献的 Spring Boot starter 中 OpenAI 模型的自定义基础 URL 支持
- [@geoand](https://github.com/geoand) 贡献的使项目的一些方面可以通过外部集成进行替换
- [@SimonVerhoeven](https://github.com/SimonVerhoeven) 贡献的如果模型（如 Vertex）没有 ToolSpecification，则不使用期望一个的 generate 方法
- [@ThomasVitale](https://github.com/ThomasVitale) 贡献的为自定义 Spring Boot 属性包含元数据
- [@jmgang](https://github.com/jmgang) 贡献的从 S3 加载文档的支持
- [@Martin7-1](https://github.com/Martin7-1) 贡献的添加 BOM 以管理工件
- [@kevin-wu-os](https://github.com/kevin-wu-os) 贡献的 [PGVector](https://github.com/pgvector/pgvector) 集成
- [@jkuipers](https://github.com/jkuipers) 贡献的 Spring Boot 配置属性的自动补全支持
- [@Martin7-1](https://github.com/Martin7-1) 贡献的 [Ollama](https://ollama.ai/) 集成
- [@geoand](https://github.com/geoand) 贡献的使 AiServices 可以通过外部实现进行替换
- [@geoand](https://github.com/geoand) 贡献的为 HuggingFace 引入 SPI
- [@Artur-](https://github.com/Artur-) 贡献的允许在 Pinecone 中使用不同于 text_segment 的元数据键
- [@Heezer](https://github.com/Heezer) 贡献的 VertexAI 支持中的拼写错误修复
- [@pascalconfluent](https://github.com/pascalconfluent) 贡献的 [Amazon Bedrock](https://aws.amazon.com/bedrock/) 集成
- [@benedictstrube](https://github.com/benedictstrube) 贡献的将 Memory Id 添加到工具方法调用中

### 详细解释

1. **OpenSearch 集成**：
   - OpenSearch 是一个开源的搜索和分析引擎，基于 Elasticsearch。通过与 OpenSearch 的集成，`langchain4j` 项目现在可以使用 OpenSearch 进行高效的搜索和分析任务。

2. **Vertex AI：以 5 个一批的方式嵌入**：
   - Vertex AI 现在支持以 5 个一批的方式嵌入数据，这提高了嵌入任务的效率和性能。

3. **Milvus 数据库名称配置支持**：
   - Milvus 现在支持配置数据库名称，这使得开发者可以更灵活地管理和使用 Milvus 数据库。

4. **OpenAI：添加了设置自定义 Tokenizer 的选项，将默认超时时间增加到 60 秒**：
   - OpenAI 现在支持设置自定义 Tokenizer，并且默认超时时间增加到 60 秒，这提高了系统的灵活性和稳定性。

5. **Azure OpenAI：将默认超时时间增加到 60 秒**：
   - Azure OpenAI 的默认超时时间增加到 60 秒，这提高了系统的稳定性和可靠性。

6. **Spring Boot starter 中 OpenAI 模型的自定义基础 URL 支持**：
   - Spring Boot starter 现在支持 OpenAI 模型的自定义基础 URL，这使得开发者可以更灵活地配置和使用 OpenAI 模型。

7. **使项目的一些方面可以通过外部集成进行替换**：
   - 项目的一些方面现在可以通过外部集成进行替换，这提高了系统的灵活性和可扩展性。

8. **如果模型（如 Vertex）没有 ToolSpecification，则不使用期望一个的 generate 方法**：
   - 如果模型（如 Vertex）没有 ToolSpecification，则不使用期望一个的 generate 方法，这提高了系统的稳定性和可靠性。

9. **为自定义 Spring Boot 属性包含元数据**：
   - 为自定义 Spring Boot 属性包含元数据，这提高了系统的可维护性和可读性。

10. **从 S3 加载文档的支持**：
    - 现在支持从 S3 加载文档，这扩展了系统的数据源支持。

11. **添加 BOM 以管理工件**：
    - 添加 BOM（Bill of Materials）以管理工件，这提高了项目的依赖管理和可维护性。

12. **PGVector 集成**：
    - PGVector 是一个用于 PostgreSQL 的向量扩展。通过与 PGVector 的集成，`langchain4j` 项目现在可以使用 PGVector 进行高效的向量搜索和检索。

13. **Spring Boot 配置属性的自动补全支持**：
    - 现在支持 Spring Boot 配置属性的自动补全，这提高了开发效率和代码质量。

14. **Ollama 集成**：
    - Ollama 是一个开源的机器学习平台。通过与 Ollama 的集成，`langchain4j` 项目现在可以使用 Ollama 进行机器学习任务。

15. **使 AiServices 可以通过外部实现进行替换**：
    - AiServices 现在可以通过外部实现进行替换，这提高了系统的灵活性和可扩展性。

16. **为 HuggingFace 引入 SPI**：
    - 为 HuggingFace 引入 SPI（Service Provider Interface），这提高了系统的灵活性和可扩展性。

17. **允许在 Pinecone 中使用不同于 text_segment 的元数据键**：
    - 现在允许在 Pinecone 中使用不同于 text_segment 的元数据键，这提高了系统的灵活性和可定制性。

18. **VertexAI 支持中的拼写错误修复**：
    - 修复了 VertexAI 支持中的拼写错误，这提高了系统的稳定性和可读性。

19. **Amazon Bedrock 集成**：
    - Amazon Bedrock 是 AWS 提供的一个机器学习平台。通过与 Amazon Bedrock 的集成，`langchain4j` 项目现在可以使用 Amazon Bedrock 进行机器学习任务。

20. **将 Memory Id 添加到工具方法调用中**：
    - 将 Memory Id 添加到工具方法调用中，这提高了系统的灵活性和可扩展性。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和灵活性。通过添加与 OpenSearch、PGVector、Ollama、Amazon Bedrock 等的集成，以及添加对自定义 Tokenizer、自定义基础 URL、自动补全、SPI 等的支持，`langchain4j` 项目现在更加强大、灵活和易用。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.23.0

Sep 29, 2023

- 模型 API 更新：返回 `Response<T>` 而不是 `T`。`Response<T>` 包含 token 使用情况和完成原因。
- 所有模型和嵌入存储集成现在位于它们自己的模块中
- [@Heezer](https://github.com/Heezer) 贡献的 [Vespa](https://vespa.ai/) 集成
- [@Martin7-1](https://github.com/Martin7-1) 贡献的 [Elasticsearch](https://www.elastic.co/) 集成
- [@Martin7-1](https://github.com/Martin7-1) 贡献的 [Redis](https://redis.io/) 集成
- [@IuriiKoval](https://github.com/IuriiKoval) 贡献的 [Milvus](https://milvus.io/) 集成
- [@clun](https://github.com/clun) 贡献的 [Astra DB](https://www.datastax.com/products/datastax-astra) 和 [Cassandra](https://cassandra.apache.org/) 集成
- 添加了对文档分割器中重叠的支持
- 一些 bug 修复和小改进

### 详细解释

1. **模型 API 更新**：
   - 模型 API 现在返回 `Response<T>` 而不是 `T`。`Response<T>` 包含 token 使用情况和完成原因，这使得开发者可以更方便地监控和分析模型的使用情况。

2. **所有模型和嵌入存储集成现在位于它们自己的模块中**：
   - 通过将所有模型和嵌入存储集成放在它们自己的模块中，`langchain4j` 项目现在更加模块化和可维护。这使得开发者可以更方便地选择和集成特定的模型和存储选项。

3. **Vespa 集成**：
   - Vespa 是一个开源的大规模并行计算引擎，用于实时搜索和机器学习。通过与 Vespa 的集成，`langchain4j` 项目现在可以使用 Vespa 进行大规模的搜索和机器学习任务。

4. **Elasticsearch 集成**：
   - Elasticsearch 是一个开源的分布式搜索和分析引擎。通过与 Elasticsearch 的集成，`langchain4j` 项目现在可以使用 Elasticsearch 进行高效的搜索和分析任务。

5. **Redis 集成**：
   - Redis 是一个开源的内存数据结构存储，常用作数据库、缓存和消息代理。通过与 Redis 的集成，`langchain4j` 项目现在可以使用 Redis 进行高效的缓存和数据存储。

6. **Milvus 集成**：
   - Milvus 是一个开源的向量数据库，用于存储和查询嵌入向量。通过与 Milvus 的集成，`langchain4j` 项目现在可以使用 Milvus 进行高效的向量搜索和检索。

7. **Astra DB 和 Cassandra 集成**：
   - Astra DB 是基于 Apache Cassandra 的云数据库服务，Cassandra 是一个开源的分布式数据库。通过与 Astra DB 和 Cassandra 的集成，`langchain4j` 项目现在可以使用这些数据库进行高效的分布式数据存储和查询。

8. **添加了对文档分割器中重叠的支持**：
   - 文档分割器（Document Splitters）现在支持重叠分割，这使得文档分割更加灵活和高效。

9. **一些 bug 修复和小改进**：
   - 这些更新包括一些 bug 修复和性能改进，提高了项目的稳定性和性能。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和灵活性。通过更新模型 API、将所有模型和嵌入存储集成放在它们自己的模块中、添加与 Vespa、Elasticsearch、Redis、Milvus、Astra DB 和 Cassandra 的集成，以及添加对文档分割器中重叠的支持，`langchain4j` 项目现在更加强大、灵活和易用。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.22.0

Aug 30, 2023

- [@kuraleta](https://github.com/kuraleta) 贡献的 [Google Vertex AI](https://cloud.google.com/vertex-ai) 集成
- 离线 [基于嵌入的文本分类](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/embedding/classification/EmbeddingModelTextClassifierExample.java)
- 重构了 [文档分割器](https://github.com/langchain4j/langchain4j/blob/main/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/DocumentSplitters.java)
- `InMemoryEmbeddingStore` 现在可以轻松地持久化和恢复，参见 `serializeToJson()`、`serializeToFile()`、`fromJson()` 和 `fromFile()`
- 添加了在 `HtmlTextExtractor` 中轻松提取元数据的选项
- 修复了 [#126](https://github.com/langchain4j/langchain4j/issues/126) 和 [#127](https://github.com/langchain4j/langchain4j/issues/127)

### 详细解释

1. **Google Vertex AI 集成**：
   - Google Vertex AI 是 Google Cloud 提供的一个机器学习平台。通过与 Google Vertex AI 的集成，`langchain4j` 项目现在可以使用 Google Cloud 提供的机器学习服务，从而扩展了其应用范围。

2. **离线基于嵌入的文本分类**：
   - 基于嵌入的文本分类是一种使用嵌入向量进行文本分类的技术。通过添加离线文本分类功能，`langchain4j` 项目现在可以在没有网络连接的情况下进行文本分类，提高了系统的灵活性和可用性。

3. **重构了文档分割器**：
   - 文档分割器（Document Splitters）用于将文档分割成更小的片段。通过重构文档分割器，`langchain4j` 项目现在可以更高效和灵活地处理文档分割任务，提高了系统的性能和可维护性。

4. **InMemoryEmbeddingStore 的持久化和恢复**：
   - `InMemoryEmbeddingStore` 是一个内存中的嵌入存储，用于存储和查询嵌入向量。通过添加 `serializeToJson()`、`serializeToFile()`、`fromJson()` 和 `fromFile()` 方法，`InMemoryEmbeddingStore` 现在可以轻松地持久化和恢复，从而提高了系统的可靠性和可维护性。

5. **在 HtmlTextExtractor 中轻松提取元数据**：
   - `HtmlTextExtractor` 是一个用于从 HTML 文档中提取文本的工具。通过添加轻松提取元数据的选项，`HtmlTextExtractor` 现在可以更方便地处理和提取 HTML 文档中的元数据，提高了系统的灵活性和功能性。

6. **修复了 #126 和 #127**：
   - 这些更新修复了项目中的一些 bug，提高了系统的稳定性和可靠性。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和灵活性。通过与 Google Vertex AI 的集成、添加离线文本分类功能、重构文档分割器、支持 `InMemoryEmbeddingStore` 的持久化和恢复、在 `HtmlTextExtractor` 中轻松提取元数据，以及修复一些 bug，`langchain4j` 项目现在更加强大、灵活和易用。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.21.0

Aug 19, 2023

- [@kuraleta](https://github.com/kuraleta) 贡献的 [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview) 集成
- [@jiangsier-xyz](https://github.com/jiangsier-xyz) 贡献的 Qwen 模型（DashScope）集成
- [@kuraleta](https://github.com/kuraleta) 贡献的 [Chroma 集成](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/embedding/store/ChromaEmbeddingStoreExample.java)
- [持久化 ChatMemory 的支持](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ServiceWithPersistentMemoryForEachUserExample.java)

### 详细解释

1. **Azure OpenAI 集成**：
   - Azure OpenAI 是微软 Azure 平台上提供的 OpenAI 服务。通过与 Azure OpenAI 的集成，`langchain4j` 项目现在可以使用 Azure 提供的 OpenAI 服务，从而扩展了其应用范围。

2. **Qwen 模型（DashScope）集成**：
   - Qwen 模型是 DashScope 提供的一种大型语言模型。通过与 Qwen 模型的集成，`langchain4j` 项目现在可以使用 DashScope 提供的模型，从而增加了模型的多样性和选择性。

3. **Chroma 集成**：
   - Chroma 是一个开源的向量数据库，用于存储和查询嵌入向量。通过与 Chroma 的集成，`langchain4j` 项目现在可以使用 Chroma 作为嵌入存储，从而增强了向量搜索和检索的能力。

4. **持久化 ChatMemory 的支持**：
   - 持久化 ChatMemory 允许系统将聊天记忆保存到持久化存储中，例如数据库或文件系统。通过支持持久化 ChatMemory，系统可以更好地管理用户之间的对话历史，确保即使在系统重启后，对话上下文仍然保持一致。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和灵活性。通过与 Azure OpenAI、Qwen 模型（DashScope）和 Chroma 的集成，项目现在可以使用更多的模型和存储选项，从而扩展了其应用范围。同时，持久化 ChatMemory 的支持使得系统可以更好地管理用户之间的对话历史，提高了系统的稳定性和一致性。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.20.0

Aug 14, 2023

添加了为 OpenAI 模型设置代理的选项（[#93](https://github.com/langchain4j/langchain4j/pull/93)）

添加了更多预打包的进程内嵌入模型（[#91](https://github.com/langchain4j/langchain4j/pull/91)）：

- [bge-small-en](https://huggingface.co/BAAI/bge-small-en)
- [bge-small-zh](https://huggingface.co/BAAI/bge-small-zh)

InMemoryEmbeddingStore：从最高到最低返回匹配项（[#90](https://github.com/langchain4j/langchain4j/pull/90)）

### 详细解释

1. **为 OpenAI 模型设置代理的选项**：
   - 通过添加设置代理的选项，开发者可以在使用 OpenAI 模型时通过代理服务器进行请求。这对于需要通过代理访问外部服务的场景非常有用，例如在企业内部网络中。

2. **更多预打包的进程内嵌入模型**：
   - 这些新添加的嵌入模型（如 `bge-small-en` 和 `bge-small-zh`）是预打包的进程内嵌入模型，可以在同一个 Java 进程中运行，无需外部依赖。这提高了系统的独立性和灵活性。

3. **InMemoryEmbeddingStore：从最高到最低返回匹配项**：
   - `InMemoryEmbeddingStore` 是一个内存中的嵌入存储，用于存储和查询嵌入向量。通过从最高到最低返回匹配项，系统可以更方便地处理和排序查询结果，提高了查询的效率和准确性。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和灵活性。通过添加为 OpenAI 模型设置代理的选项，开发者可以更方便地处理代理访问。新添加的预打包进程内嵌入模型提高了系统的独立性和灵活性。同时，`InMemoryEmbeddingStore` 的改进使得查询结果的排序更加方便和高效。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.19.0

Aug 10, 2023

- [Weaviate 集成](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/embedding/store/WeaviateEmbeddingStoreExample.java) 由 [@Heezer](https://github.com/Heezer) 贡献
- [DOC、XLS 和 PPT 加载器](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/DocumentLoaderExamples.java) 由 [@oognuyh](https://github.com/oognuyh) 贡献
- [每个用户的单独聊天记忆](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ServiceWithMemoryForEachUserExample.java)
- [自定义进程内嵌入模型](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/embedding/model/InProcessEmbeddingModelExamples.java)
- 添加了大量 Javadoc
- 添加了 `DocumentTransformer` 及其第一个实现：`HtmlTextExtractor`
- `OpenAiTokenizer` 现在更加精确，可以估计工具/函数的 token
- 在 `OpenAiChatModel` 和 `OpenAiStreamingChatModel` 中添加了强制执行工具/函数的选项
- 一些 bug 修复和改进

### 详细解释

1. **Weaviate 集成**：
   - Weaviate 是一个开源的向量搜索引擎，用于存储和查询嵌入向量。通过与 Weaviate 的集成，`langchain4j` 项目现在可以使用 Weaviate 作为嵌入存储，从而增强了向量搜索和检索的能力。

2. **DOC、XLS 和 PPT 加载器**：
   - 这些加载器（Document Loaders）用于从 DOC、XLS 和 PPT 文件中加载文档。通过添加这些加载器，`langchain4j` 项目现在可以处理更多类型的文档，从而扩展了其应用范围。

3. **每个用户的单独聊天记忆**：
   - 通过为每个用户提供单独的聊天记忆，系统可以更好地管理用户之间的对话历史，确保每个用户的对话上下文独立且一致。

4. **自定义进程内嵌入模型**：
   - 自定义进程内嵌入模型允许开发者使用自定义的嵌入模型，而无需外部依赖。这提高了系统的灵活性和可定制性。

5. **添加了大量 Javadoc**：
   - Javadoc 是 Java 的文档生成工具，用于生成代码文档。通过添加大量 Javadoc，`langchain4j` 项目的文档更加完善，有助于开发者更好地理解和使用项目。

6. **DocumentTransformer 及其第一个实现：HtmlTextExtractor**：
   - `DocumentTransformer` 是一个用于转换文档的接口，`HtmlTextExtractor` 是其第一个实现，用于从 HTML 文档中提取文本。这增强了项目处理不同格式文档的能力。

7. **OpenAiTokenizer 现在更加精确**：
   - `OpenAiTokenizer` 现在可以更精确地估计工具/函数的 token 数量，从而提高了 token 计数的准确性。

8. **强制执行工具/函数的选项**：
   - 在 `OpenAiChatModel` 和 `OpenAiStreamingChatModel` 中添加了强制执行工具/函数的选项，使得开发者可以更灵活地控制模型的行为。

9. **一些 bug 修复和改进**：
   - 这些更新包括一些 bug 修复和性能改进，提高了项目的稳定性和性能。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和易用性。通过与 Weaviate 的集成、添加更多文档加载器、为每个用户提供单独的聊天记忆、支持自定义进程内嵌入模型、添加大量 Javadoc、增强 `OpenAiTokenizer` 的精确性、添加强制执行工具/函数的选项，以及进行一些 bug 修复和改进，`langchain4j` 项目现在更加强大、灵活和易用。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.18.0

Jul 27, 2023

- 我们添加了与 [LocalAI](https://localai.io/) 的集成。现在，你可以使用本地托管的 LLM！
- 添加了对 [AI 服务中响应流的支持](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ServiceWithStreamingExample.java)。

### 详细解释

1. **与 LocalAI 的集成**：
   - LocalAI 是一个本地托管的大型语言模型（LLM）平台。通过与 LocalAI 的集成，`langchain4j` 项目现在可以使用本地托管的 LLM，而无需依赖外部服务。这提高了系统的独立性和安全性，同时减少了对外部服务的依赖。

2. **AI 服务中响应流的支持**：
   - 响应流（Response Streaming）是一种在生成响应时逐步发送数据的技术。通过添加对响应流的支持，`langchain4j` 项目现在可以在生成响应时逐步发送数据，而不是一次性发送所有数据。这提高了用户体验，特别是在处理大文本或复杂任务时。

### 结论

这些更新增强了 `langchain4j` 项目的功能和灵活性。通过与 LocalAI 的集成，开发者可以使用本地托管的 LLM，提高了系统的独立性和安全性。同时，对响应流的支持使得生成响应时可以逐步发送数据，提高了用户体验。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.17.0

Jul 22, 2023

添加了进程内嵌入模型：

- all-minilm-l6-v2
- all-minilm-l6-v2-q
- e5-small-v2
- e5-small-v2-q

这个想法是为了让用户能够在同一个 Java 进程中嵌入文档/文本，而无需任何外部依赖。ONNX Runtime 用于在 JVM 内部运行模型。每个模型都位于其自己的 Maven 模块（在 jar 文件中）。

### 详细解释

1. **进程内嵌入模型**：
   - 这些模型（如 `all-minilm-l6-v2`、`all-minilm-l6-v2-q`、`e5-small-v2`、`e5-small-v2-q`）是用于文本嵌入的模型。它们可以在同一个 Java 进程中运行，无需外部依赖，从而简化了部署和集成过程。

2. **ONNX Runtime**：
   - ONNX Runtime 是一个用于运行 ONNX 模型的开源库。通过使用 ONNX Runtime，这些嵌入模型可以在 JVM 内部运行，从而避免了对外部服务的依赖。

3. **每个模型位于其自己的 Maven 模块**：
   - 每个嵌入模型都位于其自己的 Maven 模块中，这意味着它们被打包在单独的 jar 文件中。这使得开发者可以按需选择和集成特定的模型，而不需要加载所有模型。

### 结论

这些更新为 `langchain4j` 项目添加了进程内嵌入模型，使得用户可以在同一个 Java 进程中嵌入文档/文本，而无需外部依赖。通过使用 ONNX Runtime 在 JVM 内部运行模型，这些更新简化了部署和集成过程。每个模型位于其自己的 Maven 模块中，使得开发者可以按需选择和集成特定的模型，提高了项目的灵活性和可维护性。

## 0.16.0

Jul 18, 2023

为 OpenAI 模型添加了更多请求参数：

- top_p
- max_tokens
- presence_penalty
- frequency_penalty

### 详细解释

1. **top_p**：
   - `top_p`（也称为核采样或概率质量阈值）是一个用于控制生成文本多样性的参数。它决定了在生成下一个词时，模型会选择概率质量总和达到 `top_p` 的词。例如，如果 `top_p` 设置为 0.9，模型将只选择概率质量总和达到 90% 的词。

2. **max_tokens**：
   - `max_tokens` 是一个用于控制生成文本长度的参数。它决定了生成文本的最大 token 数量。例如，如果 `max_tokens` 设置为 50，模型将生成最多 50 个 token 的文本。

3. **presence_penalty**：
   - `presence_penalty` 是一个用于控制生成文本中重复出现某个词的惩罚参数。它决定了模型在生成文本时，对已经出现过的词的惩罚程度。较高的 `presence_penalty` 值会减少重复词的出现。

4. **frequency_penalty**：
   - `frequency_penalty` 是一个用于控制生成文本中词频的惩罚参数。它决定了模型在生成文本时，对高频词的惩罚程度。较高的 `frequency_penalty` 值会减少高频词的出现。

### 结论

这些更新为 OpenAI 模型添加了更多的请求参数，使得开发者可以更精细地控制生成文本的多样性、长度、重复词和高频词。通过调整这些参数，开发者可以更好地满足特定应用场景的需求，提高生成文本的质量和相关性。

## 0.15.0

Jul 18, 2023

你现在可以免费试用 OpenAI 的 `gpt-3.5-turbo` 和 `text-embedding-ada-002` 模型，无需 OpenAI 账户和密钥！只需使用 API 密钥 "demo"。

### 详细解释

1. **免费试用 OpenAI 模型**：
   - `gpt-3.5-turbo` 是 OpenAI 提供的一个强大的语言模型，适用于各种自然语言处理任务。`text-embedding-ada-002` 是一个用于生成文本嵌入的模型，可以将文本转换为向量表示。

2. **无需 OpenAI 账户和密钥**：
   - 通常，使用 OpenAI 的模型需要注册 OpenAI 账户并获取 API 密钥。但现在，通过 `langchain4j`，你可以直接使用预设的 API 密钥 "demo" 来免费试用这些模型，无需注册和获取密钥。

3. **简化试用流程**：
   - 通过提供预设的 API 密钥 "demo"，`langchain4j` 简化了试用 OpenAI 模型的流程，使得开发者可以更方便地体验和评估这些模型的性能和功能。

### 结论

这些更新使得开发者可以更方便地试用 OpenAI 的 `gpt-3.5-turbo` 和 `text-embedding-ada-002` 模型，无需注册 OpenAI 账户和获取密钥。通过使用预设的 API 密钥 "demo"，开发者可以快速体验和评估这些模型的性能和功能，从而更好地决定是否将其集成到自己的项目中。

## 0.14.0

Jul 16, 2023

- 通过移除 `Result` 类简化了所有模型的 API。现在模型直接返回结果（`AiMessage`/`Embedding`/`Moderation` 等），而不将其包装在 `Result` 对象中。
- 修复了一个阻止在 AI 服务中使用 `@UserMessage` 的错误。

### 详细解释

1. **简化了所有模型的 API**：
   - 通过移除 `Result` 类，模型的 API 变得更加简洁。现在，模型直接返回结果（例如 `AiMessage`、`Embedding`、`Moderation` 等），而不需要将其包装在 `Result` 对象中。这简化了代码的调用和处理，提高了代码的可读性和易用性。

2. **修复了阻止在 AI 服务中使用 `@UserMessage` 的错误**：
   - `@UserMessage` 是一个注解，用于标识 AI 服务中的用户消息。修复了阻止在 AI 服务中使用这个注解的错误，使得开发者可以更方便地管理和处理用户消息，提高了代码的可靠性和功能性。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和易用性。通过简化模型的 API，开发者可以更方便地调用和处理模型返回的结果。同时，修复了阻止在 AI 服务中使用 `@UserMessage` 的错误，提高了代码的可靠性和功能性。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.13.0

Jul 15, 2023

- 添加了 EmbeddingStoreIngestor
- 重新设计了文档加载器（参见 FileSystemDocumentLoader）
- 简化了 ConversationalRetrievalChain
- 将 DocumentSegment 重命名为 TextSegment
- 添加了数值类型的输出解析器
- 为 AI 服务添加了 @UserName
- Fixed [24](https://github.com/langchain4j/langchain4j/issues/24)

### 详细解释

1. **添加了 EmbeddingStoreIngestor**：
   - `EmbeddingStoreIngestor` 是一个用于将嵌入向量存储到嵌入存储中的工具。它可以帮助开发者自动将文档或文本转换为嵌入向量，并存储到指定的嵌入存储中，以便后续的检索和查询。

2. **重新设计了文档加载器**：
   - 文档加载器（Document Loaders）用于从各种来源加载文档。重新设计后的文档加载器（例如 `FileSystemDocumentLoader`）可能提供了更灵活和易用的接口，简化了文档加载的过程。

3. **简化了 ConversationalRetrievalChain**：
   - `ConversationalRetrievalChain` 是一个用于处理对话式检索的组件。通过简化这个组件，开发者可以更容易地集成和使用它，从而实现更高效的对话式检索功能。

4. **将 DocumentSegment 重命名为 TextSegment**：
   - 将 `DocumentSegment` 重命名为 `TextSegment`，可能是因为新的名称更能反映其功能，即处理文本片段。这有助于提高代码的可读性和一致性。

5. **添加了数值类型的输出解析器**：
   - 输出解析器（Output Parsers）用于解析模型的输出。添加数值类型的输出解析器意味着现在可以更方便地处理和解析数值类型的输出，例如整数、浮点数等。

6. **为 AI 服务添加了 @UserName**：
   - `@UserName` 是一个注解，用于标识 AI 服务中的用户名。通过添加这个注解，开发者可以更方便地管理和处理用户名相关的逻辑，提高了代码的可维护性和可读性。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和易用性。通过添加 `EmbeddingStoreIngestor` 和数值类型的输出解析器，项目现在可以更方便地处理嵌入向量和数值输出。重新设计的文档加载器和简化的 `ConversationalRetrievalChain` 提高了代码的可读性和易用性。同时，`@UserName` 注解的添加使得用户名管理更加方便。这些改进有助于提高项目的整体质量和开发者的开发效率。

## 0.12.0

Jul 15, 2023

Hotfix for [#23](https://github.com/langchain4j/langchain4j/issues/23)

## 0.11.0

Jul 12, 2023

添加了 ["动态工具"](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ServiceWithDynamicToolsExample.java)：现在，LLM 可以为需要精确计算的任务生成代码，例如数学和字符串操作。这将以类似于 GPT-4 代码解释器的方式动态执行！我们使用 [Judge0，由 Rapid API 托管](https://rapidapi.com/judge0-official/api/judge0-ce/pricing) 进行代码执行。你可以订阅并每天免费执行 50 次。

### 详细解释

1. **动态工具**：
   - 动态工具（Dynamic Tools）允许大型语言模型（LLM）为需要精确计算的任务生成代码，例如数学运算和字符串操作。这些代码可以动态执行，类似于 GPT-4 的代码解释器。

2. **Judge0 代码执行**：
   - Judge0 是一个在线代码执行服务，由 Rapid API 托管。它支持多种编程语言，并提供了一个 API 接口，允许开发者提交代码并获取执行结果。通过使用 Judge0，`langchain4j` 项目可以动态执行 LLM 生成的代码。

3. **免费执行次数**：
   - 通过订阅 Judge0 服务，开发者可以每天免费执行 50 次代码。这对于开发和测试阶段非常有用，可以帮助开发者快速验证和调试生成的代码。

### 结论

这些更新增强了 `langchain4j` 项目的功能，使其能够动态执行 LLM 生成的代码，从而处理需要精确计算的任务。通过集成 Judge0 代码执行服务，开发者可以轻松地执行和验证生成的代码，提高了系统的灵活性和实用性。

## 0.10.0

Jul 6, 2023

- 现在你可以[将自定义知识库添加到“AI 服务”](https://github.com/langchain4j/langchain4j-examples/blob/main/spring-boot-example/src/test/java/dev/example/CustomerSupportApplicationTest.java)。相关信息将自动检索并整合到提示中。这样，LLM 将拥有数据的上下文，并基于此进行回答！
- 现在可以使用特殊的 `{{current_date}}`、`{{current_time}}` 和 `{{current_date_time}}` 占位符自动将当前日期和时间注入到提示中。

### 详细解释

1. **将自定义知识库添加到“AI 服务”**：
   - 通过将自定义知识库添加到“AI 服务”，系统可以自动检索和整合相关信息到提示中。这使得大型语言模型（LLM）能够基于特定的上下文数据进行回答，从而提供更准确和相关的响应。

2. **自动注入当前日期和时间**：
   - 通过使用特殊的占位符 `{{current_date}}`、`{{current_time}}` 和 `{{current_date_time}}`，系统可以自动将当前日期和时间注入到提示中。这对于需要时间敏感信息的应用非常有用，例如日程安排、事件提醒等。

### 结论

这些更新增强了 `langchain4j` 项目的功能，使其能够更好地处理自定义知识库和时间敏感信息。通过将自定义知识库整合到提示中，LLM 可以提供更准确和相关的回答。同时，自动注入当前日期和时间的功能使得系统能够处理需要时间信息的任务，提高了系统的灵活性和实用性。

## 0.9.0

Jul 3, 2023

新增Spring Boot 3支持

## 0.8.0

Jul 3, 2023

- 添加了 Spring Boot Starter：https://github.com/langchain4j/langchain4j-examples/blob/main/spring-boot-example/src/test/java/dev/example/CustomerSupportApplicationTest.java
- 添加了对 HuggingFace（聊天+语言）模型的支持

### 详细解释

1. **添加了 Spring Boot Starter**：
   - Spring Boot Starter 是一个用于简化 Spring Boot 应用程序开发的工具。通过提供预配置的依赖项和自动配置，Spring Boot Starter 可以帮助开发者快速启动和运行 Spring Boot 项目。提供的链接指向一个测试文件 `CustomerSupportApplicationTest.java`，展示了如何在 Spring Boot 项目中使用 `langchain4j`。

2. **添加了对 HuggingFace（聊天+语言）模型的支持**：
   - HuggingFace 是一个流行的开源平台，提供了大量的预训练模型，包括自然语言处理（NLP）和聊天模型。通过添加对 HuggingFace 模型的支持，`langchain4j` 项目现在可以集成和使用这些强大的预训练模型，从而增强其功能和性能。

### 结论

这些更新进一步增强了 `langchain4j` 项目的功能和易用性。通过添加 Spring Boot Starter，开发者可以更方便地集成 `langchain4j` 到他们的 Spring Boot 项目中。同时，对 HuggingFace 模型的支持为项目提供了更多的预训练模型选择，有助于实现更复杂的 AI 应用。

## 0.7.0

Jul 3, 2023

添加了对工具的支持（OpenAI 函数）：https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ServiceWithToolsExample.java

### 详细解释

1. **对工具的支持（OpenAI 函数）**：
   - OpenAI 函数（OpenAI Functions）是 OpenAI 提供的一种功能，允许开发者通过 API 调用 OpenAI 的模型来执行特定的任务或操作。这些函数可以用于自动化各种任务，如数据处理、文本生成、信息检索等。

2. **示例代码**：
   - 提供的链接指向一个示例代码文件 `ServiceWithToolsExample.java`，展示了如何在 `langchain4j` 项目中使用 OpenAI 函数。这个示例代码可以帮助开发者理解和集成 OpenAI 函数到他们的项目中。

### 结论

通过添加对 OpenAI 函数的支持，`langchain4j` 项目现在可以更方便地集成和使用 OpenAI 提供的各种功能。这为开发者提供了更多的灵活性和功能扩展能力，有助于实现更复杂的 AI 应用。

## 0.6.0

Jun 30, 2023

- 现在可以在 AiServices 中定义 ChatMemory，它会保存你的交互历史
- 添加了 OpenAI 审核模型，因此你可以审核文本、文档和消息
- 为 AiServices 添加了自动审核功能。只需在方法上方添加 [@moderate](https://github.com/moderate)，它将自动验证用户输入是否违反内容政策

### 详细解释

1. **在 AiServices 中定义 ChatMemory**：
   - `ChatMemory` 是一个用于保存聊天交互历史的组件。通过在 `AiServices` 中定义 `ChatMemory`，系统可以记录用户与 AI 的对话历史，这对于实现上下文感知的对话系统非常有用。

2. **添加了 OpenAI 审核模型**：
   - OpenAI 审核模型是一个用于内容审核的工具，可以帮助识别和过滤违反内容政策的文本、文档和消息。这有助于确保用户生成的内容符合平台的规定。

3. **为 AiServices 添加了自动审核功能**：
   - 通过在方法上方添加 `[@moderate](https://github.com/moderate)` 注解，系统可以自动验证用户输入是否违反内容政策。这简化了内容审核的过程，确保用户输入的内容符合平台的安全和合规要求。

### 结论

这些更新增强了 `AiServices` 的功能，使其能够更好地管理聊天历史、审核内容，并确保用户输入符合平台的内容政策。这些改进有助于提高系统的安全性和用户体验。

## 0.5.0

Jun 27, 2023

HuggingFace 嵌入模型现在通过 HF 推理 API 得到支持。

- HF 推理 API（HuggingFace Inference API）是 HuggingFace 提供的一个服务，允许开发者通过 API 调用预训练模型进行推理（即使用模型进行预测或生成）。

- 这意味着现在可以通过 HuggingFace 的推理 API 来使用 HuggingFace 提供的嵌入模型。这为开发者提供了更便捷的方式来集成和使用这些强大的预训练模型。

## 0.4.0

Jun 21, 2023

- 从 ai4j 更名为 langchain4j
- 重大设计变更
- 添加了“AI 服务”（声明式 AI 门面）
- 添加了更多文档加载器和分割器
- 添加了内存嵌入存储

## 0.1.0 - 0.3.0

Jun 21, 2023

Migrated from https://github.com/ai-for-java/ai4j/releases/tag/0.3.0

0.2.0：Jun 21, 2023

0.1.0：Jun 21, 2023