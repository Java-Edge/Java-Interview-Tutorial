# 2025 及未来 RAG 趋势：深入解析四大创新技术

## 0 前言

RAG是AIGC可靠性和准确性的一项关键技术。不过，RAG 也存在一些局限，如上下文处理、成本控制及面对超大数据集时的挑战。

因此，过去一年里，业界出现了许多新方法，试图弥补 RAG 的不足。

下面深入了解 2025 年RAG领域的一些最新动态。

## 1 RAG工作原理及其局限性

RAG是一种结合LLM与外部知识源的技术。具体做法是，把文档或数据库等外部知识源进行分块、向量化处理，生成所谓的向量嵌入（vector embeddings），并存储在向量数据库或其他存储系统中。当用户输入提示词时，系统可以实时检索这些数据，从而为 LLM 提供更准确、更新或更具上下文的信息。

虽然强大，但不少局限，如：

- 检索效果大程度取决于数据本身质量和更新频率
- 面对复杂查询或超大数据集时，传统的 RAG（有时也被称为“原始 RAG”）容易出现信息混淆或检索出的内容缺乏足够的细腻度

## 2 校正型 RAG（Corrective RAG）

近年来非常受欢迎的一种新方法。

### 2.1 核心思想

在检索过程中引入评估步骤，加入所谓的“自我反思”或“自我评分”机制。评估器会检查检索结果的准确性，如果达不到设定标准，系统就会重新检索（有时还会扩展到网页搜索）。这一机制通常由一个轻量级检索评估器来实现，用来衡量检索结果的相关性。

### 2.2 解决啥问题？

校正型 RAG 主要是为了应对检索不准确的问题。例如，当数据集中存在语义相近的信息时，容易混淆，而加入评估步骤可以大大提高检索结果的可靠性。

### 2.3 局限性

不过，校正型 RAG 也存在一些弊端。首先，引入评估环节不可避免地增加了延迟，因为需要额外的计算资源，可能会影响整体性能（尤其是在面向客户的实时应用中）。其次，它会增加 AI 流水线的复杂性，降低团队的开发效率，一旦出现问题，排查和修复也更困难。

此外，校正型 RAG 无法解决数据本身的问题——如果数据不准确、过时或分块不合理，仍然会影响最终效果。

### 2.4 适用场景

如需在准确性和实时数据集成之间取得平衡，这是不错选择。

## 3 自我反思型 RAG（Self-RAG）

类似校正型RAG ，也引入“自我反思”机制，但走得更远。除了评估检索结果本身之外，自我反思型 RAG 还会在是否需要检索以及如何检索方面进行更深层次的反思，并能通过反复训练不断优化。

它采用三个模型协同工作：检索器、评审器和生成器。通过这种“三位一体”的架构，自我反思型 RAG 可以生成所谓的“反思 token”。这些 token 让语言模型在推理阶段可以根据不同任务要求调整行为。

一句话，通过反馈循环不断强化自己的检索决策，最终提高整体性能。

### 3.1 解决啥问题？

和校正型 RAG 一样，自我反思型 RAG 能有效提高检索准确率。而且由于具备自我学习能力，随着时间推移，表现还能不断提升。

### 3.2 局限性

它的问题和校正型 RAG 类似，但也有自己的独特挑战。比如，自我反思机制有时会导致模型“想太多”，结果输出的信息与实际数据并不吻合。

此外，训练过程中用于反思的 token 可能会影响最终生成内容的质量或流畅度。因此，使用时需要根据实际需求权衡利弊。

### 3.3 适用场景

如果你需要模型具备较强的适应性，尤其是处理开放领域问题或复杂推理任务，自我反思型 RAG 是一个非常合适的选择。

## 4 RAG 融合（RAG-fusion）

思路与校正型 RAG、自我反思型 RAG 不同。前两者专注于“自我反思”，而 RAG-fusion 则是将多个检索到的资源（如文档、维基条目等）融合成一个批次，通过互惠排名融合（RRF）算法处理，扩展模型能够检索到的信息范围和细节。

### 4.1 解决啥问题？

RAG-fusion 主要提升了模型处理复杂背景和细节问题的能力。它能让模型给出更加连贯、详细的回答，尤其是在面对困难或多层次提示时表现更好。

### 4.2 局限性

不过，RAG-fusion 会显著增加 LLM 架构和流水线的复杂度（以及成本）。额外的步骤还可能引发性能下降等问题。

### 4.3 适用场景

如果你在客服等需要细致、连贯输出的场景中工作，RAG-fusion 是非常值得考虑的方法。

## 5 快速图谱 RAG（Fast GraphRAG）

[Fast GraphRAG](https://www.thoughtworks.com/radar/languages-and-frameworks/fastgraphrag) 是 [GraphRAG](https://www.thoughtworks.com/radar/techniques/graphrag) 的开源实现。GraphRAG 并不是简单地检索数据块，而是将数据抽取后构建成知识图谱，使得 LLM 能够像阅读地图一样理解和检索数据，提升了检索的深度和细致程度。

Fast GraphRAG 在此基础上引入了 PageRank（谷歌创始人 Larry Page 和 Sergey Brin 开发的算法），帮助系统更快速地找出知识图谱中最相关的信息。

### 5.1 解决啥问题？

Fast GraphRAG 特别擅长处理数据理解和细腻度问题。利用知识图谱，让 AI 系统对数据有更丰富的“理解”。此外，它比传统 RAG 更适合处理大规模动态数据集，能够更好应对数据更新或变化。

而且，Fast GraphRAG 相比传统 GraphRAG 成本更低、速度更快（据说能便宜 6 倍左右）。

### 5.2 局限性

不过，Fast GraphRAG 相比直接基于向量数据库的 RAG 技术还是慢一些，而且系统复杂度更高，对于很多简单场景来说，可能得不偿失。

### 5.3 适用场景

如果你面对的是超大数据集，或者对检索准确性要求极高，Fast GraphRAG 是一个非常值得考虑的选择。

## 6 RAG的未来

上面提到的方法并不全面，目前还有很多新技术正在不断涌现。

比如，有些团队正在探索多模态 RAG，不仅检索文本，还能处理图像、表格、甚至音频数据。

还有一种更彻底的替代方案叫缓存增强生成（Cache-augmented Generation），通过预加载数据到模型上下文窗口，省去了实时检索步骤，提升模型响应速度。虽然这种方式未必能提高准确性和输出质量，但对于提高效率很有帮助。

## 7 总结

可见，RAG 领域正在迅速发展。虽然生成式 AI 和大型语言模型常常成为媒体关注的焦点，但真正决定 AI 产品效果的，往往是检索技术背后的创新和实验。

当然，每种方法都有其优缺点，必须在复杂性、速度和成本之间权衡取舍。

**最重要的是，根据你的具体应用场景明确需求，认真评估不同方案，做出理性、有效的选择。**

参考：

- https://selfrag.github.io/
- https://www.thoughtworks.com/radar