# 01-RAG应用框架和解析器

## 1 开源解析和拆分文档

第三方工具去对文件解析拆分，将文件内容给提取出来，并将我们的文档内容去拆分成一个小的chunk。

常见的PDF、word、markdown、JSON、HTML，都有很好的模块去把这些文件去进行一个东西去提取。

### 1.1 优势

- 支持丰富的文档类型
- 每种文档多样化选择
- 与开源框架无缝集成



![](https://my-img.javaedge.com.cn/javaedge-blog/2024/06/704e6a30d6793c931c5db2a5afe142d5.png)

但有时效果很差，内容跟原始文件内容差别大。

## 2 PDF格式多样性



![](https://my-img.javaedge.com.cn/javaedge-blog/2024/06/96e776191774b85d9490cd0d2b3d1d4a.png)

**复杂多变的文档格式，提高解析效果十分困难**。

## 3 复杂文档格式解析问题

文档内容质量将很大程度影响最终效果，文档处理过程涉及问题：

### 3.1 内容不完整

对文档的内容提取时，可能发现提取出的文档内容会被截断。跨页形式，提取出来它的上下页，两部分内容就会被截断，导致文档内部分内容丢失，去解析图片或双栏复杂的这种格式，它会有一部分内容丢失。

### 3.2 内容错误

同一页PDF文件可能存在文本、表格、图片等混合。

PDF解析过程中，同一页它不同段落其实会也会有不同标准的一些格式。按通用格式去提取解析就遇到同页不同段落格式不标准情况。

### 3.3 文档格式

像常见PDF md文件，需要去支持把这些各类型的文档格式的文件都给提取。

### 3,4 边界场景

代码块还有单元格这些，都是我们去解析一个复杂文档格式中会遇到的一些问题。

## 4 PDF内容提取流程



![](https://my-img.javaedge.com.cn/javaedge-blog/2024/06/03bee575c2ea98f77bf868e5e885539c.png)

## 5 为啥解析文档后，要做知识片段拆分？

### 5.1 Token限制

- 绝大部分开源限制 <= 512 Tokens
- bge_base、e5_large、m3e_base、text2vector_large_chinese、multilingnal-e5-base..

### 5.2 效果影响

- 召回效果：有限向量维度下表达较多的文档信息易产生失真
- 回答效果：召回内容中包含与问题无关信息对LLM增加干扰

### 5.3 成本控制

- LLM费用：按Token计费
- 网络费用：按流量计费

## 6 Chunk（块）拆分对最终效果的影响

### 6.1 Chunk太长

信息压缩失真。

### 6.2 Chunk太短

表达缺失上下文；匹配分数容易变高。

### 6.3 Chunk跨主题

内容关系脱节。

### 原文连续内容（含表格）被截断

单个Chunk信息表达不完整，或含义相反

### 干扰信息

如空白、HTML、XML等格式，同等长度下减少有效信息、增加干扰信息

### 主题和关系丢失

缺失了主题和知识点之间的关系

## 7 改进知识的拆分方案



![](https://my-img.javaedge.com.cn/javaedge-blog/2024/06/4c4273b86a35e31104cc49f4cd8d10d1.png)

## 8 商用向量数据库AI套件

云厂商：

![](https://my-img.javaedge.com.cn/javaedge-blog/2024/06/5120078c65e3e15ae25d08cf1ec11436.png)